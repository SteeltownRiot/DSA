{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Loading Text Search in PostgreSQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<a id='PG_text' ></a>\n",
    "\n",
    "## PostgreSQL Text Storage\n",
    "\n",
    "This notebook documents the building of the `BookLines` table using the Information Retrieval (IR) based extension, _full text search_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task' /> </a>\n",
    "\n",
    "## Task at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab walks through the process of creating full text search capability within PostgreSQL for integration into other analytical processes of lines for a book (with sub-books).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database of Unstructured Text Files \n",
    "\n",
    "As was used in the lab, we are going to use this collection of text files.\n",
    "It is 4.3 megabytes of text and 31 thousand lines, sounds fun!\n",
    "\n",
    "```BASH\n",
    "$ ls /dsa/data/all_datasets/book/*\n",
    "book/1chron.txt    book/acts.txt      book/isaiah.txt    book/nahum.txt\n",
    "book/1corinth.txt  book/amos.txt      book/james.txt     book/nehemiah.txt\n",
    "book/1john.txt     book/colossia.txt  book/jeremiah.txt  book/numbers.txt\n",
    "book/1kings.txt    book/daniel.txt    book/job.txt       book/obadiah.txt\n",
    "book/1peter.txt    book/deut.txt      book/joel.txt      book/philemon.txt\n",
    "book/1samuel.txt   book/eccl.txt      book/john.txt      book/philipp.txt\n",
    "book/1thess.txt    book/ephesian.txt  book/jonah.txt     book/proverbs.txt\n",
    "book/1timothy.txt  book/esther.txt    book/joshua.txt    book/psalms.txt\n",
    "book/2chron.txt    book/exodus.txt    book/jude.txt      book/rev.txt\n",
    "book/2corinth.txt  book/ezekiel.txt   book/judges.txt    book/romans.txt\n",
    "book/2john.txt     book/ezra.txt      book/lament.txt    book/ruth.txt\n",
    "book/2kings.txt    book/galatian.txt  book/levit.txt     book/song.txt\n",
    "book/2peter.txt    book/genesis.txt   book/luke.txt      book/titus.txt\n",
    "book/2samuel.txt   book/habakkuk.txt  book/malachi.txt   book/zech.txt\n",
    "book/2thess.txt    book/haggai.txt    book/mark.txt      book/zeph.txt\n",
    "book/2timothy.txt  book/hebrews.txt   book/matthew.txt\n",
    "book/3john.txt     book/hosea.txt     book/micah.txt\n",
    "\n",
    "$ du -skh /dsa/data/all_datasets/book\n",
    "4.6M\t/dsa/data/all_datasets/book\n",
    "$ wc -l book/*  | tail -n1\n",
    "  31258 total\n",
    "```\n",
    "\n",
    "### However, now we are going to index it line-by-line.\n",
    "\n",
    "<span style=\"color:red\">\n",
    "**You will need create and load the database similarly to how you interacted with PostgreSQL in the Database and Analytics course.**\n",
    "</span>\n",
    "\n",
    "Remember a few key things:\n",
    " 1. You will use your pawprint as your user name, and the password you will type in is your normal MU password.\n",
    " 1. The database is: `dsa_student`\n",
    " 1. The database host is: `pgsql.dsa.lan`\n",
    " 1. The schema name is the same as your pawprint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build_it' /> </a>\n",
    "\n",
    "## Building a Text Retrieval Database\n",
    "\n",
    "#### Examples of all the commands are available [here](../resources/PG_Build_Lines_Search.sql). An equivalent Python implemention is [here](./Table-Setup.ipynb).\n",
    "\n",
    "You will need to open the terminal, then connect to the database to build your schema tables.\n",
    "\n",
    "<span style=\"background-color:yellow\">For the commands below, replace the schema name  with your own pawprint.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Connect with your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Initialize some variables\n",
    "mysso= <pawprint>    # this is also your schema name. \n",
    "schema=<pawprint> \n",
    "hostname='pgsql.dsa.lan'\n",
    "database='dsa_student'\n",
    "\n",
    "mypasswd = getpass.getpass(\"Type Password and hit enter\")\n",
    "connection_string = f\"postgres://{mysso}:{mypasswd}@{hostname}/{database}\"\n",
    "\n",
    "%load_ext sql\n",
    "%sql $connection_string \n",
    "\n",
    "# Then remove the password from computer memory\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create data repository (i.e table) within a database.Â¶\n",
    "\n",
    "```SQL\n",
    "-------------------------\n",
    "-- Basic Table \n",
    "-------------------------\n",
    "\n",
    "DROP TABLE IF EXISTS BookLines;\n",
    "\n",
    "CREATE TABLE BookLines(\n",
    "        id SERIAL NOT NULL,\n",
    "        name varchar(250) NOT NULL,\n",
    "        line_no INT NOT NULL,\n",
    "        line text NOT NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE BookLines\n",
    "ADD CONSTRAINT pk_BookLines PRIMARY KEY (id);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add a column that implements the vector model\n",
    "\n",
    "```SQL\n",
    "-------------------------\n",
    "-- Separate Ts_Vector column\n",
    "-------------------------\n",
    "-- TS_Vector for GIN INDEX\n",
    "ALTER TABLE BookLines\n",
    "  ADD COLUMN line_tsv_gin tsvector;\n",
    "\n",
    "UPDATE BookLines\n",
    "SET line_tsv_gin = to_tsvector('pg_catalog.english', line);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Another column that implements the vector model\n",
    "\n",
    "\n",
    "```SQL\n",
    "-- TS_Vector for GIST INDEX\n",
    "ALTER TABLE BookLines\n",
    "  ADD COLUMN line_tsv_gist tsvector;\n",
    "\n",
    "UPDATE BookLines\n",
    "SET line_tsv_gist = to_tsvector('pg_catalog.english', line);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete additional steps to build your IR backend (e.g. adding triggers and indexes)\n",
    "\n",
    "**<span style='background:yellow'>[See lab](../labs/FullText_PostgreSQL-02.ipynb)</span>**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Add triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Add indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "\n",
    "Finally, take a look at the resulting table definition:\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\dt booklines\n",
    "          List of relations\n",
    " Schema |   Name    | Type  | Owner\n",
    "--------+-----------+-------+--------\n",
    " sebcq5 | booklines | table | sebcq5\n",
    "(1 row)\n",
    "\n",
    "dsa_student=# \\d booklines\n",
    "                                       Table \"sebcq5.booklines\"\n",
    "    Column     |          Type          | Collation | Nullable |                Default\n",
    "---------------+------------------------+-----------+----------+---------------------------------------\n",
    " id            | integer                |           | not null | nextval('booklines_id_seq'::regclass)\n",
    " name          | character varying(250) |           | not null |\n",
    " line_no       | integer                |           | not null |\n",
    " line          | text                   |           | not null |\n",
    " line_tsv_gin  | tsvector               |           |          |\n",
    " line_tsv_gist | tsvector               |           |          |\n",
    "Indexes:\n",
    "    \"pk_booklines\" PRIMARY KEY, btree (id)\n",
    "    \"booklines_line\" gin (line gin_trgm_ops)\n",
    "    \"booklines_line_tsv_gin\" gin (line_tsv_gin)\n",
    "    \"booklines_line_tsv_gist\" gist (line_tsv_gist)\n",
    "Triggers:\n",
    "    tsv_gin_update BEFORE INSERT OR UPDATE ON booklines FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('line_tsv_gin', 'pg_catalog.english', 'line')\n",
    "    tsv_gist_update BEFORE INSERT OR UPDATE ON booklines FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('line_tsv_gist', 'pg_catalog.english', 'line')\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_it' /> </a>\n",
    "\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, we will use a python script with follow the basic crawling behavior\n",
    "\n",
    " 1. For each file/folder in the specified starting folder:\n",
    " 1. If it is a folder, recurse into folder and process contents\n",
    " 1. If it is a file, read contents and load into database, one line at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "# This collects a masked password from the user\n",
    "mypasswd = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysso = '<your pawprint>'  # change to your pawprint\n",
    "dbname = 'dsa_student'\n",
    "schema = '<your pawprint>' #change to your pawprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(database=dbname,\n",
    "                            user=mysso,\n",
    "                            host='pgsql.dsa.lan',\n",
    "                            password=mypasswd)\n",
    "    print(\"I am able to connect to the database\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadFile(filename):\n",
    "    '''\n",
    "    Read file contents, load into database.\n",
    "    \n",
    "    Returns: The document ID that was created\n",
    "    '''\n",
    "    line_no = 1\n",
    "    with conn, conn.cursor() as curs:\n",
    "        with open(filename, 'r') as infile:\n",
    "            for line in infile:\n",
    "                line = line.rstrip('\\n')\n",
    "                ###############################\n",
    "                # Review the Printout\n",
    "                ###############################\n",
    "                print(\"Loading: {},{} = {}\".format(filename,line_no,line))\n",
    "                ###############################\n",
    "                # When you are ready\n",
    "                # Fill in the SQL variable\n",
    "                # and Un-comment the curs.execute()\n",
    "                ###############################\n",
    "                SQL = <EDIT HERE>   \n",
    "                curs.execute(SQL,(filename,line_no,line))\n",
    "                #row_id = curs.fetchone()[0]\n",
    "                line_no += 1\n",
    "    return line_no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the cell below to test your code edits for above.\n",
    "\n",
    "##### After testing, when you are ready\n",
    " 1. comment out the print statements \n",
    " 1. Un-comment the cursor execute\n",
    " 1. Reload the edited cells\n",
    " 1. Load the cell that defines processFolder\n",
    " 1. Execute `processFolder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Dev-Testing Cell\n",
    "###############################\n",
    "\n",
    "\n",
    "lines_loaded = loadFile('/dsa/data/all_datasets/book/1peter.txt')\n",
    "print(\"Lines Loaded: {}\".format(lines_loaded))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "# Dev-Testing Cell\n",
    "# When done, change to cell type\n",
    "# Raw NBConvert\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFolder(folder):\n",
    "    '''\n",
    "    Process a folder for files and subfolders\n",
    "    '''\n",
    "    \n",
    "    print('Processing folder: ',folder)\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        \n",
    "        print(\"root = \", root)\n",
    "        \n",
    "        # Process Files\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                filename = os.path.join(root, file)\n",
    "                print('Processing File:',filename)\n",
    "                document_id = 0\n",
    "                # Comment out this line to watch the next cell walk the tree\n",
    "                lines_loaded = loadFile(filename)\n",
    "                print(\"Lines Loaded: {}\".format(lines_loaded))\n",
    "                \n",
    "            elif file.endswith(\".html\"):\n",
    "                print(\"HTML Files Not Handled Yet\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# Launch the Parsing\n",
    "###########################\n",
    "\n",
    "\n",
    "processFolder('/dsa/data/all_datasets/book');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example, similar output for the above is available [here](../resources/PG_FTS_Lines_Load.txt).\n",
    "\n",
    "### Check the Results\n",
    "\n",
    "```SQL\n",
    "dsa_student=# select count(*),sum(length(line)) from sebcq5.booklines;\n",
    " count |   sum\n",
    "-------+---------\n",
    " 31365 | 4329283\n",
    "(1 row)                                   \n",
    "```\n",
    "\n",
    "#### 31K lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at a random line that was added:\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\x \n",
    "Expanded display is on.\n",
    "dsa_student=# select * from BookLines where id = 9352;\n",
    "-[ RECORD 1 ]-+-------------------------------------------------------------------------------------------\n",
    "id            | 9352\n",
    "name          | /dsa/data/all_datasets/book/ephesian.txt\n",
    "line_no       | 135\n",
    "line          | 6:3: That it may be well with thee, and thou mayest live long on the earth.\n",
    "line_tsv_gin  | '3':2 '6':1 'earth':17 'live':13 'long':14 'may':5 'mayest':12 'thee':9 'thou':11 'well':7\n",
    "line_tsv_gist | '3':2 '6':1 'earth':17 'live':13 'long':14 'may':5 'mayest':12 'thee':9 'thou':11 'well':7\n",
    "```\n",
    "\n",
    "Notice that we have built a document vector that is stemmed and has removed common (stop) words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
