{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Loading Text Search in PostgreSQL - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task' /> </a>\n",
    "\n",
    "## Task at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we are going to walk through the process of creating full text search capability within PostgreSQL for integration into other analytical processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database of Unstructured Text Files \n",
    "\n",
    "In this module we will explore the Bible scripture. It is 4.6 megabytes of text and 31 thousand lines. These files are physically located here: `/dsa/data/all_datasets/book/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls /dsa/data/all_datasets/book/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -skh /dsa/data/all_datasets/book   # disk usgae (du) for these documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l /dsa/data/all_datasets/book/*  | tail -n1  #num of lines in these documents; wc -l counts lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build_it' /> </a>\n",
    "\n",
    "## Building a Text Retrieval Database\n",
    "\n",
    "<span style=\"color:red\">\n",
    "**You will need create and load the database similarly to how you interacted with PostgreSQL in the Database and Analytics course.**\n",
    "</span>\n",
    "\n",
    "Remember a few key things:\n",
    " 1. You will use your pawprint as your user name, and the password you will type in is your normal MU password.\n",
    " 1. The database is: `dsa_student`\n",
    " 1. The database host is: `pgsql.dsa.lan`\n",
    " 1. The schema name is the same as your pawprint.\n",
    "\n",
    "There are 3 ways to create/manipulate a database (See the Database Course): \n",
    "\n",
    "* Using Jupyter SQL magic function (this notebook uses sql magic when possible)\n",
    "* Using psql console (see [here](../resources/PG_Build_Bible_Search.sql) for the necessary script)\n",
    "    * You will need to open the terminal, then connect to the database to build your schema tables.\n",
    "* Programatic access using psycopg or SQLAlchemy (See this [notebook](./Table-Setup.ipynb).)\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"background-color:yellow\">For the commands below, replace the schema name with your own pawprint.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing for speeding up full text search. \n",
    "\n",
    "In the previous lab, we explored `tsvector`, `tsquery`, and associated function. For speeding up full text search, postgres also uses two kinds of indexes: GIN ([Generalized Inverted Indexes](https://www.postgresql.org/docs/current/gin.html)) and GiST ([Generalized Search Tree](https://www.postgresql.org/docs/current/gist.html)). \n",
    "\n",
    "From the Postgres docs: \n",
    "> GIN is designed for handling cases where the items to be indexed are composite values, and the queries to be handled by the index need to search for element values that appear within the composite items. For example, the items could be documents, and the queries could be searches for documents containing specific words.\n",
    "\n",
    "GiST indexes are most useful when you have data that can in some way overlap with the value of that same column but from another row. The best thing about GiST indexes: if you have say a geometry data type and you want to see if two polygons contained some point. In one case a specific point may be contained within box, while another point only exists within one polygon. The most common datatypes where you want to leverage GiST indexes are:\n",
    "\n",
    "* Geometry types\n",
    "* Text when dealing with full-text search\n",
    "\n",
    "\n",
    "Check these articles to learn about various indexing system in postgres \n",
    "* https://www.citusdata.com/blog/2017/10/17/tour-of-postgres-index-types/\n",
    "* https://www.quest.com/community/blogs/b/database-management/posts/a-guide-to-using-postgres-indexes. \n",
    "\n",
    "Here is the official document about GIN and GiST index https://www.postgresql.org/docs/9.1/textsearch-indexes.html\n",
    "\n",
    "> In choosing which index type to use, GiST or GIN, consider these performance differences:\n",
    "> * GIN index lookups are about three times faster than GiST\n",
    "> * GIN indexes take about three times longer to build than GiST\n",
    "> * GIN indexes are moderately slower to update than GiST indexes, but about 10 times slower if fast-update support was disabled [...]\n",
    "> * GIN indexes are two-to-three times larger than GiST indexes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Connect with your database.\n",
    "\n",
    "You might remember that a database has a set of schemas and a schema has a set of tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Initialize some variables\n",
    "mysso=\"<your pawprint>\"    # this is also your schema name. \n",
    "schema='<your pawprint>' \n",
    "hostname='pgsql.dsa.lan'\n",
    "database='dsa_student'\n",
    "\n",
    "mypasswd = getpass.getpass(\"Type Password and hit enter\")\n",
    "connection_string = f\"postgres://{mysso}:{mypasswd}@{hostname}/{database}\"\n",
    "\n",
    "%load_ext sql\n",
    "%sql $connection_string \n",
    "\n",
    "# Then remove the password from computer memory\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the connection by printing the first 3 tables in this schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select * \n",
    "from information_schema.tables\n",
    "where table_schema = '<your pawprint>'\n",
    "limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create data repository (i.e table) within a database.\n",
    "\n",
    "We store all the books in this database. One table is enough to store the book contents. This table has three fields: id, filename, and content. \n",
    "\n",
    "```SQL\n",
    "DROP TABLE IF EXISTS BookSearch;\n",
    "\n",
    "\n",
    "CREATE TABLE BookSearch(\n",
    "    id SERIAL NOT NULL,\n",
    "    name varchar(250) NOT NULL,\n",
    "    content text NOT NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE BookSearch\n",
    "ADD CONSTRAINT pk_BookSearch PRIMARY KEY (id);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS BookSearch;\n",
    "\n",
    "\n",
    "CREATE TABLE BookSearch(\n",
    "    id SERIAL NOT NULL,\n",
    "    name varchar(250) NOT NULL,\n",
    "    content text NOT NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE BookSearch\n",
    "ADD CONSTRAINT pk_BookSearch PRIMARY KEY (id);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add a column that implements the vector model, then parse the data into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add another column in the BookSearch table that can store vector representation of the content column. We wil also create index for this column later. \n",
    "\n",
    "```SQL\n",
    "-- TS_Vector of GIN INDEX\n",
    "\n",
    "ALTER TABLE BookSearch \n",
    "  ADD COLUMN content_tsv_gin tsvector;\n",
    "\n",
    "    \n",
    "-- now update the above column by parsing the content column\n",
    "\n",
    "UPDATE BookSearch \n",
    "SET content_tsv_gin = to_tsvector('pg_catalog.english', content);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- TS_Vector of GIN INDEX\n",
    "\n",
    "ALTER TABLE BookSearch \n",
    "  ADD COLUMN content_tsv_gin tsvector;\n",
    "\n",
    "    \n",
    "-- now update the above column by parsing the content column. Note: the following is only required if we\n",
    "-- already have some rows in the table.\n",
    "\n",
    "UPDATE BookSearch \n",
    "SET content_tsv_gin = to_tsvector('pg_catalog.english', content);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add another column that implements the vector model, then parse the data into it.\n",
    "\n",
    "Why are we adding an identical ts_vector? We plan to show two indexes: GIN and GiST. If we create two indexes on the same column, only one of them will be visible. That's why we are creating an identical column. \n",
    "\n",
    "```SQL\n",
    "-- TS_Vector for GIST INDEX\n",
    "ALTER TABLE BookSearch \n",
    "  ADD COLUMN content_tsv_gist tsvector;\n",
    "\n",
    "UPDATE BookSearch \n",
    "SET content_tsv_gist = to_tsvector('pg_catalog.english', content);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- TS_Vector for GIST INDEX\n",
    "ALTER TABLE BookSearch \n",
    "  ADD COLUMN content_tsv_gist tsvector;\n",
    "\n",
    "-- now update the above column by parsing the content column. Note: the following is only required if we\n",
    "-- already have some rows in the table.\n",
    "\n",
    "UPDATE BookSearch \n",
    "SET content_tsv_gist = to_tsvector('pg_catalog.english', content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Set up database triggers to parse all new content loaded into the vector models.\n",
    "\n",
    "When using a separate column to store the tsvector representation of your documents, it is necessary to create a trigger to update the tsvector column when the document content columns change. Two built-in trigger functions are available for this, or you can write your own. These triggers are as follows: \n",
    "\n",
    "```SQL\n",
    "tsvector_update_trigger(tsvector_column_name, config_name, text_column_name [, ... ])\n",
    "tsvector_update_trigger_column(tsvector_column_name, config_column_name, text_column_name [, ... ])\n",
    "```\n",
    "\n",
    "See here https://www.postgresql.org/docs/9.5/textsearch-features.html to learn about these trigger functions. \n",
    "\n",
    "Now we create two triggers for the two tsvector columns we created earlier. \n",
    "\n",
    "```SQL\n",
    "--TRIGGER\n",
    "CREATE TRIGGER tsv_gin_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON BookSearch \n",
    "\tFOR EACH ROW \n",
    "\tEXECUTE PROCEDURE \n",
    "\ttsvector_update_trigger(content_tsv_gin,'pg_catalog.english',content);\n",
    "\n",
    "CREATE TRIGGER tsv_gist_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON BookSearch \n",
    "\tFOR EACH ROW \n",
    "    EXECUTE PROCEDURE\n",
    "\ttsvector_update_trigger(content_tsv_gist,'pg_catalog.english',content);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TRIGGER IF EXISTS tsv_gin_update on BookSearch;\n",
    "\n",
    "CREATE TRIGGER tsv_gin_update \n",
    "    BEFORE INSERT OR UPDATE\n",
    "    ON BookSearch \n",
    "    FOR EACH ROW \n",
    "    EXECUTE PROCEDURE \n",
    "    tsvector_update_trigger(content_tsv_gin,'pg_catalog.english',content);\n",
    "\n",
    "DROP TRIGGER IF EXISTS tsv_gist_update on BookSearch;\n",
    "    \n",
    "CREATE TRIGGER tsv_gist_update \n",
    "    BEFORE INSERT OR UPDATE\n",
    "    ON BookSearch \n",
    "    FOR EACH ROW \n",
    "    EXECUTE PROCEDURE\n",
    "    tsvector_update_trigger(content_tsv_gist,'pg_catalog.english',content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Add a specialized indexing to the vector models.\n",
    "\n",
    "```SQL\n",
    "-------------------------\n",
    "-- Create Indexes\n",
    "-------------------------\n",
    "\n",
    "-- Index on content (Trigram needed,to use Gin Index)\n",
    "-- CREATE EXTENSION pg_trgm;  -- Done by DB Admin\n",
    "\n",
    "CREATE INDEX BookSearch_content\n",
    "ON BookSearch USING GIN(content gin_trgm_ops);\n",
    "\n",
    "-- GIN INDEX on content_tsv_gin\n",
    "CREATE INDEX BookSearch_content_tsv_gin\n",
    "ON BookSearch USING GIN(content_tsv_gin);\n",
    "\n",
    "-- GIST INDEX on content_tsv_gist\n",
    "CREATE INDEX BookSearch_content_tsv_gist\n",
    "ON BookSearch USING GIST(content_tsv_gist);\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Index on content (Trigram needed,to use Gin Index)\n",
    "-- CREATE EXTENSION pg_trgm;  -- Done by DB Admin\n",
    "\n",
    "CREATE INDEX BookSearch_content\n",
    "ON BookSearch USING GIN(content gin_trgm_ops);\n",
    "\n",
    "-- GIN INDEX on content_tsv_gin\n",
    "CREATE INDEX BookSearch_content_tsv_gin\n",
    "ON BookSearch USING GIN(content_tsv_gin);\n",
    "\n",
    "-- GIST INDEX on content_tsv_gist\n",
    "CREATE INDEX BookSearch_content_tsv_gist\n",
    "ON BookSearch USING GIST(content_tsv_gist);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "NOTE: Read briefly about [trigrams](https://en.wikipedia.org/wiki/Trigram), you may see these again with computational linguistics later.\n",
    "\n",
    "Finally, take a look at the resulting table definition: (you need to open psql on terminal to see this)\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\dt \n",
    "          List of relations\n",
    " Schema |    Name    | Type  | Owner\n",
    "--------+------------+-------+--------\n",
    " sebcq5 | booksearch | table | sebcq5\n",
    "(1 row)\n",
    "\n",
    "dsa_student=# \\d booksearch\n",
    "                                         Table \"sebcq5.booksearch\"\n",
    "      Column      |          Type          | Collation | Nullable |                Default\n",
    "------------------+------------------------+-----------+----------+----------------------------------------\n",
    " id               | integer                |           | not null | nextval('booksearch_id_seq'::regclass)\n",
    " name             | character varying(250) |           | not null |\n",
    " content          | text                   |           | not null |\n",
    " content_tsv_gin  | tsvector               |           |          |\n",
    " content_tsv_gist | tsvector               |           |          |\n",
    "Indexes:\n",
    "    \"pk_booksearch\" PRIMARY KEY, btree (id)\n",
    "    \"booksearch_content\" gin (content gin_trgm_ops)\n",
    "    \"booksearch_content_tsv_gin\" gin (content_tsv_gin)\n",
    "    \"booksearch_content_tsv_gist\" gist (content_tsv_gist)\n",
    "Triggers:\n",
    "    tsv_gin_update BEFORE INSERT OR UPDATE ON booksearch FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('content_tsv_gin','pg_catalog.english', 'content')\n",
    "    tsv_gist_update BEFORE INSERT OR UPDATE ON booksearch FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('content_tsv_gist', 'pg_catalog.english', 'content')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT table_schema, table_name, column_name, data_type\n",
    "FROM information_schema.columns\n",
    "WHERE table_schema = 'khx3p' AND table_name = 'booksearch';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_it' /> </a>\n",
    "\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, we will use a python script with follow the basic crawling behavior\n",
    "\n",
    " 1. For each file/folder in the specified starting folder:\n",
    " 1. If it is a folder, recurse into folder and process contents\n",
    " 1. If it is a file, read contents and load into database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "# This collects a masked password from the user\n",
    "mypasswd = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysso = '<your pawprint>'\n",
    "dbname = 'dsa_student'\n",
    "schema = '<your pawprint>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(database=dbname,\n",
    "                            user=mysso,\n",
    "                            host='pgsql.dsa.lan',\n",
    "                            password=mypasswd)\n",
    "    print(\"I am able to connect to the database\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function process a document \n",
    "\n",
    "def load_file(filename):\n",
    "    '''\n",
    "    Read file contents, load into database.\n",
    "    \n",
    "    Returns: The document ID that was created\n",
    "    '''\n",
    "    with open(filename, 'r') as infile:\n",
    "        content=infile.read()\n",
    "        with conn, conn.cursor() as curs:\n",
    "            # Note the schema name usage\n",
    "            SQL = \"INSERT INTO booksearch(name,content) VALUES (%s,%s) RETURNING id;\"    \n",
    "            curs.execute(SQL,(filename,content))\n",
    "            document_id = curs.fetchone()[0]\n",
    "    return document_id \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above function\n",
    "\n",
    "sample_file = \"/dsa/data/all_datasets/book/zeph.txt\"\n",
    "load_file(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select * from booksearch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "delete from booksearch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_folder(folder):\n",
    "    '''\n",
    "    Process a folder for files and subfolders\n",
    "    '''\n",
    "    \n",
    "    print('Processing folder: ',folder)\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        \n",
    "        print(\"root = \", root)\n",
    "        \n",
    "        # Process Files\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                filename = os.path.join(root, file)\n",
    "                print('Processing File:',filename)\n",
    "                # Comment out this line to watch the next cell walk the tree\n",
    "                document_id = load_file(filename)\n",
    "                print(\"Document {} created\".format(document_id))\n",
    "                \n",
    "            elif file.endswith(\".html\"):\n",
    "                print(\"HTML Files Not Handled Yet\")\n",
    "\n",
    "        # Recurse into subfolders\n",
    "        for d in dirs:\n",
    "            print(\"recursing into \",d)\n",
    "            process_folder(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Launch the Parsing\n",
    "###########################\n",
    "\n",
    "process_folder('/dsa/data/all_datasets/book');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The output for  the above code should look similar to [here](../resources/PG_FTS_load_output.txt).\n",
    "\n",
    "### Check the Results\n",
    "\n",
    "```SQL\n",
    "dsa_student=# select count(*),sum(length(content)) from booksearch;\n",
    " count |   sum\n",
    "-------+---------\n",
    "    67 | 4346482\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "#### Looking at the last file that I added a few levels deep to test!\n",
    "\n",
    "```SQL\n",
    "dsa_student=# \\x \n",
    "Expanded display is on.\n",
    "dsa_student=# select * from booksearch where id = 67;\n",
    "-[ RECORD 1 ]----+--------------------------------------------------------------------\n",
    "id               | 67\n",
    "name             | /dsa/data/all_datasets/book/one_level_down/two_levels_down/test.txt\n",
    "content          | This is just a test file                                           +\n",
    "                 |\n",
    "content_tsv_gin  | 'file':6 'test':5\n",
    "content_tsv_gist | 'file':6 'test':5\n",
    "```\n",
    "\n",
    "Notice that we have built a document vector that has removed common and stop words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select count(*),sum(length(content)) from booksearch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select * from booksearch limit 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select * from booksearch where id = 67;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='search_me' /> </a>\n",
    "\n",
    "## Executing Queries\n",
    "### Google-lite...very very lite\n",
    "\n",
    "Recall, the database is now a collection of vectors. \n",
    "\n",
    "Now, to query the database we must convert our queries into vectors for matching.\n",
    "\n",
    "For full documentation, you will want to consult the PostgreSQL documentation.\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch.html\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch-controls.html\n",
    "  * https://www.postgresql.org/docs/current/static/textsearch-features.html\n",
    "\n",
    "Below we show a few examples, which you can play with and adjust as you see fit.\n",
    "\n",
    "<span style=\"color:red\">**The following cells are for you to execute.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic connection with the DSA Readonly User\n",
    "\n",
    "We will now search this database as readonly user. To prepare your DB to be read, you will need to grant the `dsa_ro_user` schema access and select privileges on your table.\n",
    "\n",
    "```SQL\n",
    "GRANT USAGE ON SCHEMA sebcq5 TO dsa_ro_user;  -- NOTE: change to your schema\n",
    "GRANT SELECT ON BookSearch TO dsa_ro_user;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "GRANT USAGE ON SCHEMA <your pawprint> TO dsa_ro_user;\n",
    "GRANT SELECT ON BookSearch TO dsa_ro_user;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now connect to the database with `dsa_ro_user` user id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgres://dsa_ro_user:readonly@pgsql.dsa.lan/dsa_student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A couple of query examples\n",
    "\n",
    "NOTE:\n",
    "```\n",
    "%%sql\n",
    "```\n",
    "... allows multi-line SQL statements\n",
    "\n",
    "NOTE:\n",
    "Query terms can be joined with boolean operators, \n",
    "  * `|` is \"or\" \n",
    "  * `&` is \"and\"\n",
    "  \n",
    "  \n",
    "**<span style=\"background:yellow\">Change the schema to your schema name in each query below!</span>**\n",
    "\n",
    "Note: we can also rank the queries in postgres. Check here (https://www.postgresql.org/docs/9.6/textsearch-controls.html) for two ranking functions. \n",
    "\n",
    "```SQL\n",
    "ts_rank([ weights float4[], ] vector tsvector, query tsquery [, normalization integer ]) returns float4\n",
    "\n",
    "ts_rank_cd([ weights float4[], ] vector tsvector, query tsquery [, normalization integer ]) returns float4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, to_tsquery('test | file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, to_tsquery('test & file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, to_tsquery('love') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, plainto_tsquery('test file') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT plainto_tsquery('test file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, plainto_tsquery('love') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please explore different queries\n",
    "\n",
    "  1. Explore changing the query below.\n",
    "  2. Observer how the ranking score is changed with different queries and different numbers of search terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT id,name, ts_rank_cd(content_tsv_gin, query) AS rank\n",
    "FROM <yourschema>.booksearch, plainto_tsquery('stone pride') query\n",
    "WHERE query @@ content_tsv_gin\n",
    "ORDER BY rank DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, the `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "448.352px",
    "width": "251.989px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
