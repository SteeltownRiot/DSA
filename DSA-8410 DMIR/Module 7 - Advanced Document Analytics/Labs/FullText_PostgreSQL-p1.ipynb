{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Loading Text Search in PostgreSQL-Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<a id='PG_text' ></a>\n",
    "\n",
    "## PostgreSQL Text Storage\n",
    "\n",
    "PostgreSQL is the most powerful and flexible open-source relational database management system (RDBMS) available.\n",
    "As you may know, it is actually an Object-Relational DBMS (ORDBMS).\n",
    "Beyond these capabilities, PostgreSQL supports extensibility including No-SQL extensions, JSON extensions, and Spatial / Geospatial extensions.\n",
    "There are many extensions available, and **this notebook focuses on an Information Retrieval (IR) based extension, _full text search_.**\n",
    "\n",
    "### PostgreSQL Textual Field (column) Types\n",
    "\n",
    "| Name                             | Description                |  \n",
    "| -------------------------------- | -------------------------- |  \n",
    "| character varying(n), varchar(n) | variable-length with limit |  \n",
    "| character(n), char(n)            | fixed-length, blank padded |  \n",
    "| text                             | variable unlimited length  |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the manual\n",
    "\n",
    "In addition, PostgreSQL provides the `text` type, which stores strings of any length. \n",
    "Although the type `text` is not in the SQL standard, several other SQL database management systems have it as well.\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "In any case, the longest possible character string that can be stored is about 1 GB. \n",
    "\n",
    "...\n",
    "\n",
    "**If you desire to store long strings with no specific upper limit, use text or character varying without a length specifier, rather than making up an arbitrary length limit.**\n",
    "\n",
    "---\n",
    "So, `text` fields have no size limit, per se.\n",
    "In reality, the underlying computer system may impose some limits.\n",
    "\n",
    "In the details of things, `text` and other large objects are optimized for storage by being compressed into backup tables to accelerate relational operations on other columns.\n",
    " * When you have spare time, [read about PostgreSQL TOASTing](https://www.postgresql.org/docs/9.5/static/storage-toast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task' /> </a>\n",
    "\n",
    "## Task at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building systems to access unstructured data has been a long-standing challenge in computer and information science. Luckily for this course, we have two stellar tools: **PostgreSQL** and **Python**. We have seen full text search with Python in the pervious lab. \n",
    "\n",
    "\n",
    "For this lab, we are going to walk through the process of creating full text search capability within PostgreSQL at the basic level. We will be using a toy dataset for this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build_it' /> </a>\n",
    "\n",
    "## Building a Text Retrieval Database\n",
    "\n",
    "<span style=\"color:red\">\n",
    "**You will need create and load the database similarly to how you interacted with PostgreSQL in the Database and Analytics course.**\n",
    "</span>\n",
    "\n",
    "Remember a few key things:\n",
    " 1. You will use your pawprint as your user name, and the password you will type in is your normal MU password.\n",
    " 1. The database is: `dsa_student`\n",
    " 1. The database host is: `pgsql.dsa.lan`\n",
    " 1. The schema name is the same as your pawprint.\n",
    "\n",
    "There are 3 ways to create/manipulate a database (See the Database Course): \n",
    "\n",
    "* Using Jupyter SQL magic function \n",
    "* Using psql console \n",
    "* Programatic access using psycopg or SQLAlchemy\n",
    "\n",
    "\n",
    "<span style=\"background-color:yellow\">For the commands below, replace the schema name with your own pawprint.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Search in SQL\n",
    "\n",
    "In the Database and Analytics course, we explored queries with text column. E.g., we have used LIKE operator. \n",
    "\n",
    "```SQL\n",
    "SELECT column_name FROM table_name WHERE column_name LIKE 'pattern';  \n",
    "```\n",
    "\n",
    "We use wildcards such as % (as in LIKE 'a%' to search for columns that start with \"a\"), and _ (as in LIKE '_r%' to find any values that have an \"r\" in the second position). In PostgreSQL we can also use ILIKE to ignore cases. For simple columns (e.g. name, address), this type of search may serve our purpose. But for a column that contains a text document, searching with regular expression will be very slow. \n",
    "\n",
    "A more effective way to approach this problem is by getting a semantic vector for all of the words contained in a document, that is, a language-specific representation of such words. So, when you search for a word like \"jump\", you will match all instances of the word and its tenses, even if you searched for \"jumped\" or \"jumping\". Additionally, you won't be searching the full document itself (which is slow), but the vector (which is fast).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tsvector and tsquery\n",
    "\n",
    "For facilitating full-text search, Postgres offers two data types: tsvector and tsquery.\n",
    "\n",
    "From https://www.postgresql.org/docs/10/datatype-textsearch.html: \n",
    "\n",
    "> PostgreSQL provides two data types that are designed to support full text search, which is the activity of searching through a collection of natural-language documents to locate those that best match a query. The **tsvector** type represents a document in a form optimized for text search; the **tsquery** type similarly represents a text query. \n",
    "\n",
    "\n",
    "PostgreSQL has two functions that help us create these two data types. \n",
    "\n",
    "* `to_tsvector`: for creating a list of tokens (the tsvector data type, where ts stands for \"text search\");\n",
    "* `to_tsquery`: for querying the vector for occurrences of certain words or phrases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's connect to the database and create a toy table that can store a text document. We will discuss about these data types at the appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Connect with your database.\n",
    "\n",
    "You might remember that a database has a set of schemas and a schema has a set of tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Initialize some variables\n",
    "mysso=\"<your pawprint>\"    # this is also your schema name. \n",
    "schema='<your pawprint>' \n",
    "hostname='pgsql.dsa.lan'\n",
    "database='dsa_student'\n",
    "\n",
    "mypasswd = getpass.getpass(\"Type Password and hit enter\")\n",
    "connection_string = f\"postgres://{mysso}:{mypasswd}@{hostname}/{database}\"\n",
    "\n",
    "%load_ext sql\n",
    "%sql $connection_string \n",
    "\n",
    "# Then remove the password from computer memory\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the connection by printing the first 5 tables in this schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select * \n",
    "from information_schema.tables\n",
    "where table_schema = '<your pawprint>'\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create data repository (i.e table) within a database.\n",
    "\n",
    "\n",
    "We store text documents in this database. One table is enough to store the text contents. This table has two fields: document_id and document_text. \n",
    "\n",
    "```SQL\n",
    "DROP TABLE IF EXISTS Documents;\n",
    "\n",
    "\n",
    "CREATE TABLE Documents(\n",
    "    document_id SERIAL NOT NULL PRIMARY KEY,\n",
    "    document_text text NOT NULL\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS Documents;\n",
    "\n",
    "\n",
    "CREATE TABLE Documents(\n",
    "    document_id SERIAL NOT NULL PRIMARY KEY,\n",
    "    document_text text NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1: Add a column that implements the vector model, then parse the data into it.\n",
    "\n",
    "Postgres allows us to parse text data and store into a vector model **tsvector**. See here to learn https://www.postgresql.org/docs/10/datatype-textsearch.html about this type of field. \n",
    "\n",
    "> A tsvector value is a sorted list of distinct lexemes, which are words that have been normalized to merge different variants of the same word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type `tsvector`  is handy in a full-text search. We can add a field in the above table that processes the content and creates a text vector representation. Before creating a field of type `tsvector` in the table, let's see how it works. A tsvector value merges different variants of the same word and removes duplicates and stopwords to create a sorted list of distinct words called lexemes (i.e, terms). So tsvector essentially represents the data as a term vector with their occurrence positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('pg_catalog.english', 'Never gonna give you up. Never gonna let you down');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the lexeme/term `gonna` occurs at postion 2 and 6 of the text. Also, the words `you`, `up`, and `down` are removed as they are stopwords. The first argument passed to `to_tsvector` is the name of a dictionary to use. Each dictionary includes a list of `stop words` that get excluded from the result. Different dictionaries have different stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT to_tsvector('pg_catalog.simple', 'Never gonna give you up. Never gonna let you down');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add another column in the BookSearch table that can store vector representation of the content column. We could have defined this column in Step 1, but we created it separately for the sake of discussion.  \n",
    "```SQL\n",
    "ALTER TABLE Documents \n",
    "  ADD COLUMN document_tokens tsvector;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "\n",
    "ALTER TABLE Documents \n",
    "  ADD COLUMN document_tokens tsvector;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Now add some records to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO documents (document_text) VALUES  \n",
    "('Pack my box with five dozen milk jugs.'),\n",
    "('Jackdaws love my big sphinx of quartz.'),\n",
    "('The five boxing wizards jump quickly.'),\n",
    "('How vexingly quick daft zebras jump!'),\n",
    "('Bright vixens jump; dozy fowl quack.'),\n",
    "('Sphinx of black quartz, judge my vow.');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from Documents;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Update the document_tokens column \n",
    "\n",
    "We will take advantage of `to_tsvector()` function for converting the document_text column and populating document_tokens column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "UPDATE documents d1  \n",
    "SET document_tokens = to_tsvector(d1.document_text)  \n",
    "FROM documents d2;  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from Documents;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have populated both document_text and document_tokens together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE from Documents;\n",
    "\n",
    "SELECT * from Documents;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO documents (document_text, document_tokens) VALUES  \n",
    "('Pack my box with five dozen liquor jugs.', to_tsvector('Pack my box with five dozen liquor jugs.')) ,\n",
    "('Jackdaws love my big sphinx of quartz.', to_tsvector('Jackdaws love my big sphinx of quartz.')),\n",
    "('The five boxing wizards jump quickly.', to_tsvector('The five boxing wizards jump quickly.')),\n",
    "('How vexingly quick daft zebras jump!', to_tsvector('How vexingly quick daft zebras jump!')),\n",
    "('Bright vixens jump; dozy fowl quack.', to_tsvector('Bright vixens jump; dozy fowl quack.')),\n",
    "('Sphinx of black quartz, judge my vow.', to_tsvector('Sphinx of black quartz, judge my vow.'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from Documents;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function that we're interested in is `to_tsquery()`, which accepts a list of words that will be checked against the normalized vector we created with `to_tsvector()`.\n",
    "\n",
    "To do this, we'll use the `@@` operator to check if tsquery matches tsvector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('fox');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searhing with 'fox' returned true. Now with \"foxes\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('foxes');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That also returns \"true\" because \"foxes\" is the plural form of \"fox\". But how about \"foxit\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('foxit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's false because the search is smart enough not to match anything that simply starts with fox unless it's related to the same semantics (meaning) of the text originally vectorized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, now with \"jumping\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('jumping');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operators: \n",
    "\n",
    "tsquery also provides a set of operators that we would expect in any decent query facility.\n",
    "\n",
    "\n",
    "##### AND operator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('fox & dog');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR operator (|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('fox | clown');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEGATION operator (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('!clown');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can, of course, combine them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT to_tsvector('The quick brown fox jumped over the lazy dog')  \n",
    "    @@ to_tsquery('fox & (dog | clown) & !queen');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform search over the Documents table that we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT document_id, document_text, document_tokens  FROM documents  \n",
    "WHERE document_tokens @@ to_tsquery('jump & quick'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AND operator doesn't make any distinction in regards to the location of words in the documents. Let's try it now with the proximity operator <->. This operator facilitate phrase search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT document_id, document_text, document_tokens FROM documents  \n",
    "WHERE document_tokens @@ to_tsquery('jump <-> quick');  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can now find words next to each other, but can you find words \"close\" to each other even if one doesn't come immediately after the other? In fact, the dash - in the proximity operator <-> is a placeholder for the amount of proximity you're searching for. Let's give some examples:\n",
    "\n",
    "Let's search for \"sphinx\" and \"quartz\" next to each other (<->):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT * FROM documents  \n",
    "WHERE document_tokens @@ to_tsquery('sphinx <-> quartz');  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's increase the proximity between \"sphinx\" and \"quartz\" to two words apart (<2>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT * FROM documents  \n",
    "WHERE document_tokens @@ to_tsquery('sphinx <2> quartz'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And three words apart (<3>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT * FROM documents  \n",
    "WHERE document_tokens @@ to_tsquery('sphinx <3> quartz');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word of caution when performing proximity search. Unlike text-search where (jump & quick) and (quick & jump) would yield the same results, phrase search is not symmetric! That is, searching for (jump <-> quick) is not the same as searching for (quick <-> jump) as the PostgreSQL engine will consider the order in which you're placing the words.\n",
    "\n",
    "And just so you know, <-> is really syntactic sugar for the tsquery_phrase() function; so `to_tsquery('sphinx <3> quartz')` is equivalent to `tsquery_phrase('sphinx', 'quartz', 3)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "The reason why full-text search works really fast is because of the tsvector data type, which works as an index for the document's context. That being said, the cost of the operation is generating this index, which is something you would normally need to do only once (unless the document gets updated).\n",
    "\n",
    "A good practice, therefore, is to store the vectors alongside with the documents, just as we did in our phrase search example. This way, you can profit from the speedup and flexibility of the tsvector/tsquery pair, while paying the small cost of generating and storing the document tokens.\n",
    "\n",
    "In the next lab, we will how can create index for this tsvector to make it more faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, the `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "448.352px",
    "width": "251.989px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
