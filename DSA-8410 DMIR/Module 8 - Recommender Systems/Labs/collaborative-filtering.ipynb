{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "989ca8ad-c205-4c89-95f5-0678f63e90c1",
    "_uuid": "9c02125458024687b9bc5e80309c0d73ad3bd822"
   },
   "source": [
    "# Recommender Systems in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4fd4b09-74b8-4e31-a934-920bedb8dac6",
    "_uuid": "3f8d6760d36ba5a1ff7999831c6d893b2be6c94f"
   },
   "source": [
    "This notebook is adapted from [this](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101) Kaggle notebook which provides a practical introduction to the main recommender system (RecSys) techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd1c7313-f898-4d87-a281-b405ad2bb006",
    "_uuid": "23c5f6f635d1ede5e6fa2ebecb7b6a4ede99a50b"
   },
   "source": [
    "In this notebook, we use a dataset available on Kaggle Datasets: [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop). We will demonstrate how to implement **popularity model**, **collaborative filtering**, **content-based filtering** and **hybrid methods** in Python, for the task of providing personalized recommendations to the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "719f3966-e6fd-49c8-9f60-7bd741542450",
    "_uuid": "b61cd3125a7f8f991fc1bda85ae3cd26f74090ae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f5c826d-f3d5-42d3-a7e6-0343a44cdc9f",
    "_uuid": "26f1f70fd978957b26f8884fc5f82bfe9475c666"
   },
   "source": [
    "# Loading data: CI&T Deskdrop dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c48b62c-ad3b-4218-8fb2-2f0e86a16edc",
    "_uuid": "650c279eddc846a48274346e045cfb6e1f8895d5"
   },
   "source": [
    "In this section, we load the [Deskdrop dataset](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop), which contains a real sample of 12 months logs (Mar. 2016 - Feb. 2017) from CI&T's Internal Communication platform (DeskDrop). It contains about 73k logged users interactions on more than 3k public articles shared in the platform.\n",
    "It is composed of two CSV files:  \n",
    "- **shared_articles.csv**\n",
    "- **users_interactions.csv**\n",
    "\n",
    "Take a look in this kernels for a better picture of the dataset: \n",
    "- Deskdrop datasets EDA \n",
    "- DeskDrop Articles Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9ee29ff-1fee-4dc9-a3cb-e5301c17fded",
    "_uuid": "1e66e976d34d4e28f5a92241b0ea82a2a66363ea"
   },
   "source": [
    "## shared_articles.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f09d2247-a40c-4aaf-90ce-15a8721a3036",
    "_uuid": "e64f4fa8a4751274bd2d37a0f45d2d3d664d6c3e"
   },
   "source": [
    "Contains information about the articles shared in the platform. Each article has its sharing date (timestamp), the original url, title, content in plain text, the article' lang (Portuguese: pt or English: en) and information about the user who shared the article (author).\n",
    "\n",
    "There are two possible event types at a given timestamp: \n",
    "- CONTENT SHARED: The article was shared in the platform and is available for users. \n",
    "- CONTENT REMOVED: The article was removed from the platform and not available for further recommendation.\n",
    "\n",
    "For the sake of simplicity, we only consider here the \"CONTENT SHARED\" event type, assuming (naively) that all articles were available during the whole one year period. For a more precise evaluation (and higher accuracy), only articles that were available at a given time should be recommended, but we let this exercice for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e601f966-d03f-4edc-886f-ca3d511a8045",
    "_uuid": "569c301bd128f66f29b4d97c34171e4d1712015a"
   },
   "outputs": [],
   "source": [
    "filepath = '/dsa/data/DSA-8410/deskdrop/shared_articles.csv'\n",
    "\n",
    "articles_df = pd.read_csv(filepath)\n",
    "print(f\"Number of articles = {articles_df.shape[0]}\")\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "print(f\"Number of content shared type articles = {articles_df.shape[0]}\")\n",
    "articles_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "487936d5-d7b3-487d-9ef1-e3ba1e4bc421",
    "_uuid": "3f96f2d88fa86814e2fa1273d80f26d2559823fd"
   },
   "source": [
    "## users_interactions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "325b8db8-ef44-4b59-8138-2a59bd02d66e",
    "_uuid": "86694f1b80b04b8f9b961148fb265f355f202b26"
   },
   "source": [
    "Contains logs of user interactions on shared articles. It can be joined to **articles_shared.csv** by **contentId** column.\n",
    "\n",
    "The eventType values are:  \n",
    "- **VIEW**: The user has opened the article. \n",
    "- **LIKE**: The user has liked the article. \n",
    "- **COMMENT CREATED**: The user created a comment in the article. \n",
    "- **FOLLOW**: The user chose to be notified on any new comment in the article. \n",
    "- **BOOKMARK**: The user has bookmarked the article for easy return in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "445d39ec-f6b0-4155-9f92-0a2540918bd1",
    "_uuid": "9829842326037e364de457f832deceae074d6164"
   },
   "outputs": [],
   "source": [
    "\n",
    "filepath = '/dsa/data/DSA-8410/deskdrop/users_interactions.csv'\n",
    "\n",
    "\n",
    "interactions_df = pd.read_csv(filepath)\n",
    "interactions_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "585f81a5-c6ff-4399-bbec-901c41fc7285",
    "_uuid": "6abb0af8474eabb50be7a9e6496bfa75ec1b2bd9"
   },
   "source": [
    "## Data munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bad1a6c9-0258-4b89-85f9-bec89a523662",
    "_uuid": "84c2e91561d5de6afa7c45c173022193664c770e"
   },
   "source": [
    "As there are different interactions types, we associate them with a weight or strength, assuming that, for example, a comment in an article indicates a higher interest of the user on the item than a like, or than a simple view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3239c376-05b8-4a58-9afc-f6f57f67405f",
    "_uuid": "b06f8c0b082f0ad07bf773a5ad2fae33c1f7acc2"
   },
   "outputs": [],
   "source": [
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "\n",
    "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c92aa80-2926-44db-b358-c4c32de806c4",
    "_uuid": "91100a395fdf4fb20df02c8d248072457c980b5d"
   },
   "source": [
    "Recommender systems have a problem known as ***user cold-start***, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences. For this reason, we are keeping in the dataset only users with at leas 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bad1d8ea-9b67-4a47-80c5-87a5e55c4f38",
    "_uuid": "1698c88340183baa7f3ebb8c3b60eaa8e6ca708f"
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size() \\\n",
    "                                             .groupby('personId').size()\n",
    "print(f'# users: {len(users_interactions_count_df)}')\n",
    "users_with_enough_interactions_df = users_interactions_count_df[\n",
    "                                    users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "print(f'# users with at least 5 interactions: {len(users_with_enough_interactions_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e79a418-a9d6-4e01-9f38-9b290a645626",
    "_uuid": "0f428a4c6e76f95de7ea328dc33c6539389ae5f0"
   },
   "outputs": [],
   "source": [
    "print(f'# of interactions: {len(interactions_df)}')\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               on = 'personId')\n",
    "print(f'# of interactions from users with at least 5 interactions: {len(interactions_from_selected_users_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b81f2aae-4672-4ae7-aee5-f2c8f49ed863",
    "_uuid": "db9ae42791a79461ff11a462d142eae3d6c23e88"
   },
   "source": [
    "In Deskdrop, users are allowed to view an article many times, and interact with them in different ways (eg. like or comment). Thus, to model the user interest on a given article, we aggregate all the interactions the user has performed in an item by a weighted sum of interaction type strength and apply a log transformation to smooth the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54c82dd1-1102-4f11-ac6a-7993f8e5e842",
    "_uuid": "dcd64b20b47cf2c365341303ff410626a801f7a6"
   },
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)    # 1 is added to avoid 0 score\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "print(f'# of unique user/item interactions: {len(interactions_full_df)}')\n",
    "interactions_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7db22656-f1b2-4264-b74d-92ef7e03168e",
    "_uuid": "999dac17031a334be5a2245086e9c4655c5e8324"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c67fc79-fb30-4bb0-837d-a3097bf8b9b4",
    "_uuid": "7951a4fce829b66e1c96ef81fd33b12dac5eae0f"
   },
   "source": [
    "We can split the data into train/test sets for evaluation. A more robust evaluation approach could be to split train and test sets by a reference date, where the train set is composed by all interactions before that date, and the test set are interactions after that date. For the sake of simplicity, we chose the first random approach for this notebook, but you may want to try the second approach to better simulate how the recsys would perform in production predicting \"future\" users interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e594a5ef-255a-4d30-9ab2-7cebe12fe798",
    "_uuid": "babda61be5306281b34422dbded67675a0aab17d"
   },
   "outputs": [],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['personId'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be788cfc-2733-4184-8dfb-24d789e3b7da",
    "_uuid": "9a1ce40c5b2b7f89c2e34a8fce1adbeb0cfabf46"
   },
   "source": [
    "In Recommender Systems, there are a set metrics commonly used for evaluation. We chose to work with **Top-N accuracy metrics**, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.  \n",
    "This evaluation method works as follows:\n",
    "\n",
    "* For each user\n",
    "    * For each item the user has interacted in test set\n",
    "        * Sample 100 other items the user has never interacted.   \n",
    "        Ps. Here we naively assume those non interacted items are not relevant to the user, which might not be true, as the user may simply not be aware of those not interacted items. But let's keep this assumption.\n",
    "        * Ask the recommender model to produce a ranked list of recommended items, from a set composed one interacted item and the 100 non-interacted (\"non-relevant!) items\n",
    "        * Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
    "* Aggregate the global Top-N accuracy metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6f711db-3848-42de-9cb1-8adbe9fffbbd",
    "_uuid": "cb9da9e9269f20d347c9a7d0320da02f5b5d9cda"
   },
   "source": [
    "The Top-N accuracy metric choosen was **Recall@N** which evaluates whether the interacted item is among the top N items (hit) in the ranked list of 101 recommendations for a user.  \n",
    "Ps. Other popular ranking metrics are **NDCG@N** and **MAP@N**, whose score calculation takes into account the position of the relevant item in the ranked list (max. value if relevant item is in the first position)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f08b8ac-00c7-43db-89b6-4c6637f92ec5",
    "_uuid": "b97d86eb838b7dc3ce70ce2bc460b37f643fbcbb"
   },
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('personId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ee4bdf5-fcde-418f-accc-c51421a71d75",
    "_uuid": "4c008550d5312b45c1786407cce587eaf19b565c"
   },
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the article information.\n",
    "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e0639e7-4041-473d-a090-cd0087ce92c3",
    "_uuid": "c9612b159a8d626fe986586230b829ce2e93aff7"
   },
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['contentId'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(list(non_interacted_items), sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        \n",
    "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])]) \n",
    "            \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(\n",
    "                                               person_id, interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        \n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['contentId'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffacb568-e972-4fc8-9b14-eb647c24a003",
    "_uuid": "a43201479e662d0b8d9bac847f990543cb77b11f"
   },
   "source": [
    "# Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a553e0a-c90a-4db7-b710-3458ec5f5a7c",
    "_uuid": "f26d31f4e99f358a5a393ee438a34cf812d4de39"
   },
   "source": [
    "Collaborative Filtering (CF) has two main implementation strategies:  \n",
    "- **Memory-based**: This approach uses the memory of previous users interactions to compute users similarities based on items they've interacted (user-based approach) or compute items similarities based on the users that have interacted with them (item-based approach).  \n",
    "A typical example of this approach is User Neighbourhood-based CF, in which the top-N similar users (usually computed using Pearson correlation) for a user are selected and used to recommend items those similar users liked, but the current user have not interacted yet. This approach is very simple to implement, but usually do not scale well for many users. A nice Python implementation of this approach in available in [Crab](http://muricoca.github.io/crab/).\n",
    "- **Model-based**: This approach, models are developed using different machine learning algorithms to recommend items to users. There are many model-based CF algorithms, like neural networks, bayesian networks, clustering models, and latent factor models such as Singular Value Decomposition (SVD) and, probabilistic latent semantic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c7b68edb-45c7-44c7-bc0f-9a2d52e7f379",
    "_uuid": "bb26498296a6f90a0cb3c51e88b0ed39886c27ea"
   },
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7847c5c0-1122-4ced-86d1-a91e427969c0",
    "_uuid": "cd46a8bc46b6731b9d7f4cc0bf2c23bc99f14e1f"
   },
   "source": [
    "Latent factor models compress user-item matrix into a low-dimensional representation in terms of latent factors. One advantage of using this approach is that instead of having a high dimensional matrix containing abundant number of missing values we will be dealing with a much smaller matrix in lower-dimensional space.  \n",
    "\n",
    "A reduced presentation could be utilized for either user-based or item-based neighborhood algorithms that are presented in the previous section. There are several advantages with this paradigm. It handles the sparsity of the original matrix better than memory based ones. Also comparing similarity on the resulting matrix is much more scalable especially in dealing with large sparse datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "55cf72cb-61c0-4a38-a609-7283822ed052",
    "_uuid": "25d3c496a0e3e4935c906610dc97ed47e144c00f"
   },
   "source": [
    "Here we a use popular latent factor model named [Singular Value Decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition). There are other matrix factorization frameworks more specific to CF you might try, like [surprise](https://github.com/NicolasHug/Surprise), [mrec](https://github.com/Mendeley/mrec) or [python-recsys](https://github.com/ocelma/python-recsys).\n",
    "P.s. See an example of SVD on a movies dataset in this [blog post](https://beckernick.github.io/matrix-factorization-recommender/).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6168cd2-eea8-40ea-a153-4473950cdf08",
    "_uuid": "155b5e4618ec533b546029f94f2d5ffe39e1116f"
   },
   "source": [
    "An important decision is the number of factors to factor the user-item matrix. The higher the number of factors, the more precise is the factorization in the original matrix reconstructions. Therefore, if the model is allowed to  memorize too much details of the original matrix, it may not generalize well for data it was not trained on. Reducing the number of factors increases the model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e73bff0-3136-445a-b3d2-36b875681b8a",
    "_uuid": "4a69f34bfef5054abc9cf27769e4b563f004ed17"
   },
   "outputs": [],
   "source": [
    "#Creating a sparse pivot table with users in rows and items in columns\n",
    "users_items_pivot_matrix_df = interactions_train_df.pivot(index='personId', \n",
    "                                                          columns='contentId', \n",
    "                                                          values='eventStrength').fillna(0)\n",
    "\n",
    "users_items_pivot_matrix_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39c293cb-c8a7-49d1-a296-ade311bf2296",
    "_uuid": "38cc2200590bb84cd535669df8ee8177d81989eb"
   },
   "outputs": [],
   "source": [
    "users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
    "users_items_pivot_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "782aee35-da8d-45de-83bd-da38e44b3a43",
    "_uuid": "00ff9564c711e3d95c8b9a893c04e613249be42b"
   },
   "outputs": [],
   "source": [
    "users_ids = list(users_items_pivot_matrix_df.index)\n",
    "users_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix)\n",
    "users_items_pivot_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8eb2f704-cbf4-4fe3-9532-baab1c8db872",
    "_uuid": "6322d8e7afa0ac49f0df5451e304b394f410a056"
   },
   "outputs": [],
   "source": [
    "#The number of factors to factor the user-item matrix.\n",
    "NUMBER_OF_FACTORS_MF = 15\n",
    "\n",
    "#Performs matrix factorization of the original user item matrix\n",
    "#U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\n",
    "U, sigma, Vt = svds(users_items_pivot_sparse_matrix, k = NUMBER_OF_FACTORS_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9b0001e9-d560-4b6f-95a7-ae6605a72a2b",
    "_uuid": "7f6757eb2997a448537b4f59a77a6022f45edc87"
   },
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d59bac45-f8ac-422f-9a1f-c66063ca8235",
    "_uuid": "f1d0ab3e77b1c118c4867f71a4b55534e8ceb2f9"
   },
   "outputs": [],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "98b34c7d-674d-4b83-93f9-54e6d19ae9df",
    "_uuid": "f0807b245c6f939daae6447ad00594eaabd2c134"
   },
   "outputs": [],
   "source": [
    "sigma = np.diag(sigma)\n",
    "sigma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cf974d4-ca0c-487a-8561-7952be1d2f16",
    "_uuid": "de8f01beee0d5fad5e4cfd614b7c86c36b827958"
   },
   "source": [
    "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d8d09c7b-9a23-4e4f-a602-23ed20e18a1e",
    "_uuid": "66eafaba59d8ccf7dc1c02043881a64be1bba5d2"
   },
   "outputs": [],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_predicted_ratings_norm = (all_user_predicted_ratings - all_user_predicted_ratings.min()) \\\n",
    "                / (all_user_predicted_ratings.max() - all_user_predicted_ratings.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6664c5e4-14ab-47e2-a8ae-63699a531983",
    "_uuid": "1e6420b17affd1c786847b3f272d65a7ebb6b08e"
   },
   "outputs": [],
   "source": [
    "#Converting the reconstructed matrix back to a Pandas dataframe\n",
    "cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, \n",
    "                           columns = users_items_pivot_matrix_df.columns, \n",
    "                           index=users_ids).transpose()\n",
    "cf_preds_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9641fbce-f667-48f7-9142-85e486cc201d",
    "_uuid": "d51ffda7cbeab216ad6e1b449a6cec5000c780f4"
   },
   "outputs": [],
   "source": [
    "len(cf_preds_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80f4d589-c8de-4fcf-b60e-e4576fe0b23a",
    "_uuid": "d25926c1a7bada2dee4aacefc93da38053341189"
   },
   "outputs": [],
   "source": [
    "class CFRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, cf_predictions_df, items_df=None):\n",
    "        self.cf_predictions_df = cf_predictions_df\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        # Get and sort the user's predictions\n",
    "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
    "                                    .reset_index().rename(columns={user_id: 'recStrength'})\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(\n",
    "                                items_to_ignore)] \\\n",
    "                               .sort_values('recStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[[\n",
    "                                                          'recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "cf_recommender_model = CFRecommender(cf_preds_df, articles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4a2af7e-d368-432d-9ec5-d9229caf208a",
    "_uuid": "d80d307ff6b740b134ac2186f2659d468d3c2655"
   },
   "outputs": [],
   "source": [
    "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
    "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
    "cf_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8059422d-f93d-4879-a909-d22c8d746d60",
    "_uuid": "fe9beef019f59a65799ab58a1229874746c60765"
   },
   "source": [
    "Evaluating the Collaborative Filtering model (SVD matrix factorization), we observe that we got **Recall@5 (33%)** and **Recall@10 (46%)** values, much higher than Popularity model and Content-Based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266.534px",
    "width": "251.989px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
