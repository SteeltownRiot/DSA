{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "Random Forest is a good choice of model when you are unsure of a good initial model for particular data set and modeling situation. \n",
    "This model, similar to techniques such as ANOVA and MANOVA, will aid in your exploration of wide data.\n",
    "This exploration will help guide your selection of features and potentially choice in more complex models you apply on a dataset. \n",
    "\n",
    "Random Forests are capable of performing both regression and classification tasks. \n",
    "It helps in dimension reduction, handles missing values, accommodates outlier values and other \n",
    "essential steps of data exploration. Here, we will mainly use it to rank the variables with respect to importance. \n",
    "\n",
    "Before trying to get into the details of random forest, first review how how decision trees work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision trees** are a type of supervised learning algorithm mostly used in classification problems. \n",
    "It works for both categorical and continuous input and output variables. \n",
    "The main idea behind algorithm is to split the population or sample into two or more sub-populations \n",
    "based on a most significant differentiator in input variables.\n",
    "\n",
    "<img src=\"../images/decision_tree.png\">\n",
    "\n",
    "\n",
    "image source: [AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/)\n",
    "\n",
    "**Example:** \n",
    "Consider a problem of predicting whether a customer will pay his loan debt amount: either yes or no. \n",
    "The income of the customer is the deciding variable in this case. \n",
    "But the company doesn't have income details of all customers. \n",
    "Based on the insight that income drives this decision; \n",
    "a decision tree can be built to predict customer's income based on occupation, \n",
    "education level and sex and various other variables. \n",
    "Here a continuous variable is being predicted, income.\n",
    "\n",
    "\n",
    "A regular decision tree builds a single tree whether if its classification or regression using CART model(),\n",
    "but **Random Forest** algorithm builds multiple trees. \n",
    "A random forest can be built to classify an object based on attributes, \n",
    "each tree that is built gives a classification and votes for a class. \n",
    "The forest chooses the classification having the most votes (over all the trees in the forest) \n",
    "and in case of regression, \n",
    "it takes the average of outputs by different trees.\n",
    "\n",
    "We can illustrate this idea with iris dataset and compare the results. \n",
    "First, we will load the default iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=(data=iris)\n",
    "head(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspect the data on a graph\n",
    "\n",
    "library(ggplot2)\n",
    "qplot(Petal.Length,Petal.Width,colour=Species,data=iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install below packages for building a CART model.\n",
    "library(rpart)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** \n",
    "\n",
    "- [rpart](https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf)\n",
    "- [caret](https://cran.r-project.org/web/packages/caret/caret.pdf)\n",
    "- [Tree based models](http://www.statmethods.net/advstats/cart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the population in to training and testing sets. \n",
    "Compare the predictive power of decision tree and random forest on testing set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caTools)\n",
    "set.seed(100) # set.seed() will help us to reproduce the results.\n",
    "split = sample.split(iris_data$Species, SplitRatio=0.7)\n",
    "\n",
    "training  = subset(iris_data, split==TRUE)\n",
    "testing  = subset(iris_data, split==FALSE)\n",
    "nrow(training)\n",
    "\n",
    "nrow(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 105 observations in training set and 45 in testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a CART model. \n",
    "\"caret\" and \"rpart\" packages will be used to build the model.\n",
    "To create a more graphically appealing graph in R, \n",
    "a package called “rattle” is used to make the decision tree. \n",
    "\"Rattle\" builds more fancy and clean trees which are easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- train(Species~.,method=\"rpart\",data=training)\n",
    "\n",
    "# Code for generating decision tree plot\n",
    "rpart_fit <- rpart(Species~.,method=\"class\",data=training) \n",
    "library(rpart.plot)\n",
    "rpart.plot(rpart_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the predictive power of the CART model that is just built. \n",
    "Check for the number of misclassifications in the tree as the decision criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pred <- predict(fit, newdata=training)\n",
    "\n",
    "table(train.pred,training$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassification rate = 4/105\n",
    "3/105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are 3 misclassifications out of 105 observations. \n",
    "The misclassification rate signifies its predictive power. \n",
    "Once the model is built, it should be validated on a test set to see how well it performs on unknown data. \n",
    "This will help in verifying the model is not over fit to the data. \n",
    "In case the model is over fitted, validation will show a sharp decline in the predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.pred <- predict(fit, newdata=testing)\n",
    "\n",
    "table(test.pred,testing$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassification rate = 3/45\n",
    "4/45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The predictive power decreased in testing set as compared to training. \n",
    "This is generally true in most cases. \n",
    "The reason being, the model is trained on the training data set, and ideally generalized sufficient for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Now we will build a random forest model on iris_data to compare the results with CART model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_fit <- randomForest(Species~.,method=\"class\",data=training,importance=TRUE) \n",
    "\n",
    "\n",
    "plot(RandomForest_fit)\n",
    "legend(\"topright\", colnames(RandomForest_fit$err.rate),col=1:4,cex=0.8,fill=1:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the amount of error with the variation in the number of trees constructed. We can get a table of importance values for the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(RandomForest_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the variable importance for the classification across the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(RandomForest_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini importance: \n",
    "\n",
    "Every time a split of a node is made on variable `m`, the gini impurity criterion for the two descendent nodes is less than the parent node. \n",
    "Adding up the gini decreases for each individual variable over all trees in the forest gives a \n",
    "fast variable importance that is often very consistent with the permutation importance measure. According to the plots, Petal.Length is the most important variable. \n",
    "\n",
    "**Reference:** [Variable importance](https://en.wikipedia.org/wiki/Random_forest#Variable_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(RandomForest_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_fit <- train(Species~ .,method=\"rf\",data=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_RF_pred <- predict(RF_fit,training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(train_RF_pred,training$Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification rate in training data is 0/105. Validate to make sure that the model is not over fitted on the training data by testing on tets data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RF_pred<-predict(RF_fit,newdata=testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(test_RF_pred,testing$Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 misclassified observations out of 45, which is similar to CART model prediction power. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring variable importance using Random Forests\n",
    "\n",
    "#### Gini importance\n",
    "\n",
    "It is the mean Gini gain that is produced by a feature over all trees. Consider `RF` is the Random Forest model fitted on the data. \n",
    "\n",
    "```R\n",
    "RF <- randomForest(..., importance=TRUE)\n",
    "```\n",
    "\n",
    "There are 2 ways of checking the impoortance\n",
    "\n",
    "* `RF$importance`       **column**: MeanDecreaseGini\n",
    "\n",
    "* `importance(RF, type=2)`\n",
    "\n",
    "Note: For variables of different types, there will be a bias in favor of continuous \n",
    "variables and variables with many categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation importance\n",
    " \n",
    "The mean decrease in classification accuracy after permuting the feature over all trees:\n",
    "\n",
    "```R\n",
    "RF <- randomForest(..., importance=TRUE)\n",
    "```\n",
    "\n",
    "- `RF$importance` **column**: MeanDecreaseAccuracy\n",
    "- `importance(RF, type=1)`\n",
    "\n",
    "\n",
    "Note: For variables of different types are unbiased only when subsampling is used as in   \n",
    "`cforest(..., controls = cforest unbiased())`\n",
    "\n",
    "**Note:** The below cell takes a minute or so to execute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
