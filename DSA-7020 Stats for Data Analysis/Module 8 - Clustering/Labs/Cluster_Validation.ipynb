{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#51a2d6; font-size:24px; font-weight:700\"> Cluster Validation\n",
    "\n",
    "One of the big issues with clustering methods is that they will return clusters \n",
    "even if the data does not contain any clusters. \n",
    "Thus, it's important to assess clustering tendency before the analysis and also \n",
    "validate the quality of the results after clustering.\n",
    "\n",
    "In general clustering validation statistics can be grouped into following 4 classes. \n",
    "\n",
    "**Relative clustering validation**: \n",
    "This evaluates the clustering structure by varying different parameter values for the same algorithm \n",
    "(e.g. varying the number of clusters k). \n",
    "It’s generally used for determining the optimal number of clusters.\n",
    "\n",
    "**External clustering validation**: \n",
    "This method compares the results of a cluster analysis to an externally known result, \n",
    "such as externally provided class labels. \n",
    "Since we know the “true” cluster number in advance, \n",
    "this approach is mainly used for selecting the right clustering algorithm for a specific dataset.\n",
    "\n",
    "**Internal clustering validation**: \n",
    "This method uses internal information of the clustering process to evaluate the goodness \n",
    "of a clustering structure without reference to external information. \n",
    "It can be also used for estimating the number of clusters and the appropriate \n",
    "clustering algorithm without any external data.\n",
    "\n",
    "**Clustering stability validation**: \n",
    "This method is a special version of internal validation. \n",
    "It evaluates the consistency of a clustering result by comparing it with the clusters \n",
    "obtained after each column is removed, one at a time.\n",
    "\n",
    "We will be using following list of packages for clusters evaluation\n",
    "\n",
    "* **cluster:** For analyzing cluster silhouettes\n",
    "* **factoextra:** For visualizing clusters using ggplot2 plotting system\n",
    "* **fpc:** For computing clustering validation statistics\n",
    "* **NbClust:** For determining the optimal number of clusters in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:#ce7721; font-size:20px; font-weight:700\"> Data Preparation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will load a wholesales dataset from `/dsa/data/all_datasets/wholesale/Wholesale_customers_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data = read.csv(\"/dsa/data/all_datasets/wholesale/Wholesale_customers_data.csv\",sep=',',header=TRUE)\n",
    "head(customers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ce7721; font-size:20px; font-weight:700\"> Determine the optimal number of clusters\n",
    "\n",
    "The NbClust package will compute the optimal number of clusters for your data with a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_data = customers_data[,names(customers_data)!=('Region')]\n",
    "customers_scaled = scale(customers_data)\n",
    "# head(customers_scaled)\n",
    "# table(customers_data$Region)\n",
    "# attach(iris)\n",
    "# iris_scaled = iris[,-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nbclust:** \n",
    "This package provides 30 indices for determining the number of clusters and proposes to the user \n",
    "the best clustering scheme from the different results obtained by varying all combinations of number of clusters, \n",
    "distance measures, and clustering methods. \n",
    "\n",
    "For more info refer to the documentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(NbClust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(NbClust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute the number of clusters\n",
    "\n",
    "nb <- NbClust(customers_scaled, distance = \"euclidean\", min.nc = 2,\n",
    "        max.nc = 10, method = \"complete\", index =\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, NBclust is suggesting that we form 2 clusters.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "library(factoextra)\n",
    "fviz_nbclust(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ce7721; font-size:20px; font-weight:700\"> Clustering analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `eclust()` function in `factoextra` package. \n",
    "`eclust()` stands for enhanced clustering. \n",
    "It simplifies the workflow of clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "km.res <- eclust(customers_scaled, \"kmeans\", k = 2,nstart = 25, graph = FALSE)\n",
    "# k-means group number of each observation\n",
    "table(km.res$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize k-means clusters\n",
    "fviz_cluster(km.res, geom = \"point\", frame.type = \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the kmeans clustering with K=3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "km.res1 <- eclust(customers_scaled, \"kmeans\", k = 3,nstart = 25, graph = FALSE)\n",
    "# k-means group number of each observation\n",
    "table(km.res1$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize k-means clusters\n",
    "fviz_cluster(km.res1, geom = \"point\", frame.type = \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ce7721; font-size:20px; font-weight:700\"> Hierarchical Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced hierarchical clustering\n",
    "res.hc <- eclust(customers_scaled, \"hclust\", k = 3, method = \"complete\", graph = FALSE) \n",
    "table(res.hc$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram - THIS TAKES TIME TO PLOT \n",
    "\n",
    "fviz_dend(res.hc, rect = TRUE, show_labels = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#1576b2; font-size:18px; font-weight:700\"> Internal clustering validation measures\n",
    "\n",
    "The goal of clustering algorithms is to split the dataset into clusters of objects, such that:\n",
    "\n",
    "* the objects in the same cluster are as similar as possible and\n",
    "* the objects in different clusters are highly distinct\n",
    "\n",
    "In other words, we want the average distance within cluster to be as small as possible\n",
    "and the average distance between clusters to be as large as possible.\n",
    "\n",
    "The following measures help us evaluate the clusters internally:\n",
    "\n",
    "**Compactness:** \n",
    "measures how close are the objects within the same cluster. \n",
    "A lower within-cluster variation is an indicator of a good compactness (i.e., a good clustering). \n",
    "The different indices for evaluating the compactness of clusters are based on distance \n",
    "measures such as the cluster-wise within average/median distances between observations.\n",
    "\n",
    "**Separation:** \n",
    "measures how well-separated a cluster is from other clusters.\n",
    "The indices used as separation measures include distances between cluster centers and the \n",
    "pairwise minimum distances between objects in different clusters.\n",
    "\n",
    "**Connectivity:** \n",
    "corresponds to what extent items are placed in the same cluster as their nearest neighbors in the data space. \n",
    "The connectivity has a value between 0 and infinity and should be minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#1576b2; font-size:16px; font-weight:700\"> 1. Silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette analysis measures how well an observation is clustered and it estimates \n",
    "the average distance between clusters. \n",
    "The silhouette plot displays a measure of how close each point in one cluster is to points \n",
    "in the neighboring clusters. \n",
    "\n",
    "**Details:** \n",
    "For each observation $i$, the silhouette width $s(i)$ is defined as follows: \n",
    "Put $a(i)$ = average dissimilarity between i and all other points of the cluster to which i \n",
    "belongs (if i is the only observation in its cluster, $s(i):= 0$ without further calculations). \n",
    "For all other clusters C, put $d(i, C)$ = average dissimilarity of i to all observations of C. \n",
    "The smallest of these $d(i, C)$ is $b(i) := min_c d(i, C)$, \n",
    "and can be seen as the dissimilarity between i and its “neighbor” cluster, i.e., \n",
    "the nearest one to which it does not belong. Finally,\n",
    "\n",
    "$$s(i) := \\frac{b(i) - a(i)}{max(a(i), b(i))}$$\n",
    "\n",
    "\n",
    "The silhouette coefficient of observations can be computed using the function silhouette() in cluster package. \n",
    "\n",
    "$$silhouette(x, dist, ...)$$ where\n",
    "\n",
    "\n",
    "\n",
    "_x_: an integer vector containing the cluster assignment of observations\n",
    "\n",
    "_dist_: a dissimilarity object created by the function dist()\n",
    "\n",
    "The function silhouette() returns an object, of class silhouette which is an $n×3$ matrix with attributes. \n",
    "For each observation i, sil[i,] contains\n",
    "\n",
    "* The cluster number of each observation **i**\n",
    "* The neighbor cluster of **i** (the cluster, not containing **i**, for which the average dissimilarity between its observations and **i** is minimal)\n",
    "* The silhouette width $s_i$ of each observation\n",
    "\n",
    "\n",
    "The R code below computes silhouette analysis and a plot is generated using R base plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette coefficient of observations\n",
    "library(cluster)\n",
    "sil <- silhouette(km.res1$cluster, dist(customers_scaled))\n",
    "head(sil[, 1:3], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette width $s(i)$: \n",
    "Observations with a large $s(i)$ (almost 1) are very well clustered, a small $s(i)$ (around 0) \n",
    "means that the observation lies between two clusters, \n",
    "and observations with a negative $s(i)$ are probably placed in the wrong cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(factoextra)\n",
    "fviz_silhouette(sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the silhouette analysis can be computed using the function `summary.silhouette()` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of silhouette analysis\n",
    "\n",
    "summary(sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Samples with a negative silhouette coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette widths of each observation\n",
    "table(sil[, 1:3]<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few samples that have a negative silhouette coefficient in k-means clustering. \n",
    "This means that they are not in the right cluster.\n",
    "\n",
    "We can find the name of these samples and determine the clusters they are closer (neighbor cluster) to, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects with negative silhouette\n",
    "neg_sil_index <- which(sil[, 'sil_width'] < 0)\n",
    "sil[neg_sil_index, , drop = FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#1576b2; font-size:16px; font-weight:700\"> 2. Dunn index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dunn index is another internal clustering validation measure which can be computed as follows,\n",
    "\n",
    "* For each cluster, compute the distance between each of the objects in the cluster and the objects in the other clusters\n",
    "* Use the minimum of this pairwise distance as the inter-cluster separation (min.separation)\n",
    "* For each cluster, compute the distance between the objects in the same cluster.\n",
    "* Use the maximal intra-cluster distance (i.e maximum diameter) as the intra-cluster compactness\n",
    "* Calculate Dunn index (D) as follows:\n",
    "\n",
    "$$D=\\frac{min.separation}{max.diameter}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function `cluster.stats()` in fpc package and the `NbClust()` in NbClust \n",
    "package are used to compute Dunn index and many other indices.\n",
    "It returns a list containing many components useful for analyzing the intrinsic characteristics of a clustering:\n",
    "\n",
    "* cluster.number: number of clusters\n",
    "* cluster.size: vector containing the number of points in each cluster\n",
    "* average.distance, median.distance: vector containing the cluster-wise within average/median distances\n",
    "* average.between: average distance between clusters. We want it to be as large as possible\n",
    "* average.within: average distance within clusters. We want it to be as small as possible\n",
    "* clus.avg.silwidths: vector of cluster average silhouette widths. Recall that, the silhouette width is also an estimate of the * average distance between clusters. Its value is between 1 and -1 with a value of 1 indicating a very good cluster.\n",
    "* within.cluster.ss: a generalization of the within clusters sum of squares (k-means objective function), which is obtained if d is a Euclidean distance matrix.\n",
    "* dunn, dunn2: Dunn index\n",
    "* corrected.rand, vi: Two indexes to assess the similarity of two clusters: the corrected Rand index and Meila’s VI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute pairwise-distance matrices\n",
    "dd <- dist(customers_scaled, method =\"euclidean\")\n",
    "# Statistics for k-means clustering\n",
    "cluster.stats(dd, km.res1$cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the documentation for cluster.stats() for an explanation of all the available indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cluster.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
