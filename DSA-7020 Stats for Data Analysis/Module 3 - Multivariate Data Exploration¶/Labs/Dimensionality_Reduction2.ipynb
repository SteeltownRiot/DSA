{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction 2\n",
    "\n",
    "\n",
    "## PCA\n",
    "\n",
    " \n",
    "<span style=\"color: #cc1652; font-weight:700\"> Video explanation of PCA: </span>https://www.youtube.com/watch?v=FgakZw6K1QQ or https://www.youtube.com/watch?v=g-Hb26agBFg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull seed data down\n",
    "# Info about the bdims dataset: https://www.openintro.org/stat/data/bdims.php\n",
    "\n",
    "download.file(\"http://www.openintro.org/stat/data/bdims.RData\", destfile = \"bdims.RData\")\n",
    "load(\"bdims.RData\")\n",
    "\n",
    "names(bdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'sex', since it is a factor\n",
    "\n",
    "!names(bdims) %in% c('sex') # In base R, this returns a logical value for each column, as to whether each column \n",
    "                            # is \"not in\" the 'sex' column.  # the c() function combines the elements of the \n",
    "                            # argument to form a vector\n",
    "\n",
    "lessData <- bdims[,!names(bdims) %in% c('sex')]  # Subset the bdims df to only include those columns that are\n",
    "                                                # \"not in\" the 'sex' column.  Name this subset lessData.\n",
    "\n",
    "head(lessData)\n",
    "\n",
    "ncol(lessData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reference__: \n",
    " - http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/\n",
    " - http://www.sthda.com/english/wiki/principal-component-analysis-in-r-prcomp-vs-princomp-r-software-and-data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(lessData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "\n",
    "corrplot(cor(lessData), order='hclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Principal Components\n",
    "\n",
    "pca <- princomp(lessData, cor=TRUE)\n",
    "\n",
    "# The elements of the list (in this case, assigned to the object \"pca\") returned by the princomp() \n",
    "# function include sdev, loadings, center, scale, and scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pca) # print variance accounted for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT PCA information\n",
    "\n",
    "The __Proportion of Variance__ and __Cumulative Proportion__ help you see how important or significant the components are.  \n",
    "\n",
    "Note that the first principal component (PC) captures __0.6248721__ of the total variance.\n",
    "So PC1 accounts for about 62.5% of the total variance.\n",
    "\n",
    "By looking at the __Cumulative Proportion__, we can see that PC 1 through PC 19 capture 99% of the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings(pca) # pc loadings\n",
    "\n",
    "# In this matrix of variable loadings, the columns are eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scree Plot\n",
    "\n",
    "Next, we will look at the trend of variance captured as we progress from the first PC to the last.\n",
    "This is typically called a _Scree_ plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pca,type=\"lines\") # scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"factoextra\")\n",
    "\n",
    "fviz_eig(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that after the first two PC, the contribution to variance is very minimal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced <- pca$scores[,1:2] # the first 2 principal components\n",
    "\n",
    "# Scores returns the coordinates of the observations on the principal components.\n",
    "\n",
    "summary(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biplot: Visualization and Interpretation\n",
    "\n",
    "The biplot is a very popular way for visualization of results from PCA, as it combines both, the principal component scores and the loading vectors in a single biplot display. In R we simply call the biplot() function. The scale = 0 argument to biplot() ensures that the arrows are scaled to represent the loadings.\n",
    "\n",
    "In the biplot the observations are labeled by the observation number (e.g. the row name in data frame). The position in the plot represents the scores for the first two principal components. The original variables are shown as vectors (arrows). They begin at the origin and extend to coordinates given by the first two principal component loading vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "biplot(pca, scale=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting a Biplot\n",
    "\n",
    "\n",
    "The left and bottom axes of a biplot are a pair of principal components labeled Comp.1 and Comp.2.\n",
    "The right and top axes represents the coefficients/loadings of the variables. \n",
    "\n",
    "A biplot uses **points to represent the scores of the observations** on the principal components, and it uses **vectors to represent the coefficients of the variables** on the principal components.\n",
    "\n",
    "__Interpreting Points__: The relative location of the points can be interpreted. Points that are close together correspond to observations that have similar scores on the components displayed in the plot. To the extent that these components fit the data well, the points also correspond to observations that have similar values on the variables.\n",
    "\n",
    "The points that are close together are data members with similar projections/positions in the transformed space.\n",
    "\n",
    "\n",
    "__Interpreting Vectors__: Both the direction and length of the vectors can be interpreted. Vectors point away from the origin in some direction.\n",
    "\n",
    "A vector shows how a variable is represented by the two principal components, or how much it contributes to the principal components. For example, vectors close to horizontal mostly contribute to Comp.1; close to vertical mostly contribute to  Comp.2. The angles in between vectors show the correlation between the variables. Vectors pointing in the same direction are variables highly correlated. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
