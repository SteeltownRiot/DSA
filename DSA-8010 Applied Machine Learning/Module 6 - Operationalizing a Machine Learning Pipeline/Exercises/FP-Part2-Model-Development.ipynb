{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload your smart sampling from local file \n",
    "# ----------------------------------\n",
    "X, y, train_undersamp = joblib.load('data/sample-data-v1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2172 entries, (0, 786) to (1, 20979)\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   national_inv      2172 non-null   float64\n",
      " 1   lead_time         2172 non-null   float64\n",
      " 2   in_transit_qty    2172 non-null   float64\n",
      " 3   forecast_3_month  2172 non-null   float64\n",
      " 4   sales_1_month     2172 non-null   float64\n",
      " 5   sales_3_month     2172 non-null   float64\n",
      " 6   min_bank          2172 non-null   float64\n",
      " 7   potential_issue   2172 non-null   int64  \n",
      " 8   pieces_past_due   2172 non-null   float64\n",
      " 9   perf_6_month_avg  2172 non-null   float64\n",
      " 10  local_bo_qty      2172 non-null   float64\n",
      " 11  deck_risk         2172 non-null   int64  \n",
      " 12  oe_constraint     2172 non-null   int64  \n",
      " 13  ppap_risk         2172 non-null   int64  \n",
      " 14  stop_auto_buy     2172 non-null   int64  \n",
      " 15  rev_stop          2172 non-null   int64  \n",
      "dtypes: float64(10), int64(6)\n",
      "memory usage: 359.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Subset easier to manage size for testing pipelines\n",
    "train_undersamp_less = train_undersamp.groupby('went_on_backorder').apply(lambda x: x.sample(frac=0.1))\n",
    "train_undersamp_less = pd.DataFrame(train_undersamp_less)\n",
    "# Split back into X and y\n",
    "X_less = train_undersamp_less.iloc[:, :-1]\n",
    "y_less = train_undersamp_less.went_on_backorder\n",
    "X_less.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize/standardize the data if required; otherwise ignore. You can perform this step inside the pipeline (if required). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the dataset features\n",
      "[2.25476980e+02 6.86740331e+00 2.05004604e+01 1.89299263e+02\n",
      " 3.12697974e+01 9.27762431e+01 2.99456722e+01 2.76243094e-03\n",
      " 3.24769797e+00 7.36008287e-01 2.62154696e+00 1.85543278e-01\n",
      " 4.60405157e-04 1.36740331e-01 9.75138122e-01 0.00000000e+00]\n",
      "Variance of data\n",
      "[4.73404865e+03 5.53981953e+00 2.63649562e+02 2.80830589e+03\n",
      " 1.92019175e+02 5.76924761e+02 1.98046811e+02 5.24861878e-02\n",
      " 6.99672073e+01 2.79369433e-01 4.04502110e+01 3.88737662e-01\n",
      " 2.14521137e-02 3.43573010e-01 1.55704096e-01 1.00000000e+00]\n",
      "-----------------------------------\n",
      "# Scaled data:\n",
      "[[-0.04086924  0.20444649  0.07396007 ... -0.39799497  0.15967389\n",
      "   0.        ]\n",
      " [-0.04762878 -0.51759869  0.16498999 ... -0.39799497  0.15967389\n",
      "   0.        ]\n",
      " [-0.04699508  0.38495779 -0.07775647 ... -0.39799497  0.15967389\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.04784002  0.92649168 -0.07775647 ... -0.39799497  0.15967389\n",
      "   0.        ]\n",
      " [-0.04762878  0.20444649 -0.07775647 ... -0.39799497  0.15967389\n",
      "   0.        ]\n",
      " [-0.04213666  0.20444649 -0.07775647 ...  2.51259454  0.15967389\n",
      "   0.        ]]\n",
      "# Mean of scaled data\n",
      "[-6.54275079e-18 -3.92565047e-17  0.00000000e+00  0.00000000e+00\n",
      " -2.45353155e-18 -1.30855016e-17 -6.54275079e-18 -9.81412618e-18\n",
      "  5.72490694e-18  1.17769514e-16 -6.54275079e-18 -8.50557603e-17\n",
      "  6.54275079e-18 -3.92565047e-17 -4.57992555e-17  0.00000000e+00]\n",
      "# Variance of scaled data\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(X_less)\n",
    "X_less_scaled = scaler.transform(X_less)\n",
    "\n",
    "'''# Combine X_scaled and y\n",
    "train_under_stand = pd.DataFrame()\n",
    "train_under_stand = X_scaled\n",
    "train_under_stand.reset_index(drop = True)\n",
    "train_under_stand['went_on_backorder'] = y'''\n",
    "\n",
    "print(\"Mean of the dataset features\")\n",
    "print(scaler.mean_)\n",
    "print(\"Variance of data\")\n",
    "print(scaler.scale_)\n",
    "print(\"-\" * 35)\n",
    "\n",
    "print(\"# Scaled data:\")\n",
    "print(X_less_scaled)\n",
    "\n",
    "print(\"# Mean of scaled data\")\n",
    "print(X_less_scaled.mean(axis = 0))\n",
    "print(\"# Variance of scaled data\")\n",
    "print(X_less_scaled.std(axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#X_less_norm_comb.info()\\n#column = X.columns.values\\n#print(column)\\n#X_norm.info()\\n\\n#check = pd.DataFrame(X_norm['potential_issue'].unique())\\n#print(check)\\n\\nX_norm = pd.Series(X_less_norm_comb)\\n\\nprint('potential_issue', X_norm['potential_issue'].unique())\\nprint('/deck_risk', X_norm['deck_risk'].unique())\\nprint('/oe_constraint', X_norm['oe_constraint'].unique())\\nprint('/ppap_risk', X_norm['ppap_risk'].unique())\\nprint('/stop_auto_buy', X_norm['stop_auto_buy'].unique())\\nprint('/rev_stop', X_norm['rev_stop'].unique())\\nprint('/went_on_backorder', X_norm['went_on_backorder'].unique())\\n\\npotential_issue\\n\\nfor col in X_norm:\\n  print(X_norm[col].unique())\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset non discrete features\n",
    "X_less_for_norm = X_less[['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
    "                          'sales_1_month', 'sales_3_month', 'min_bank', 'pieces_past_due', \n",
    "                          'perf_6_month_avg', 'local_bo_qty']]\n",
    "#X_less_for_norm.info()\n",
    "\n",
    "# Subset discrete features\n",
    "X_less_discrete = pd.DataFrame(X_less[['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', \n",
    "                                       'stop_auto_buy', 'rev_stop']])\n",
    "#X_less_discrete.info()\n",
    "\n",
    "# Normalize data\n",
    "X_less_norm = pd.DataFrame(preprocessing.normalize(X_less_for_norm, axis = 0, norm = 'l2'))\n",
    "#X_less_norm = pd.DataFrame(X_less_norm)\n",
    "#X_less_norm.info()\n",
    "\n",
    "'''print('# Scaled & normalized values:')\n",
    "print(X_less_norm)\n",
    "\n",
    "print(\"# All have unit norm\")\n",
    "print(np.linalg.norm(X_less_norm, axis = 0))'''\n",
    "\n",
    "#X_less_norm.info()\n",
    "\n",
    "# Recombine discrete and nondiscrete features\n",
    "X_less_norm_comb = pd.DataFrame(pd.concat([X_less_norm, X_less_discrete]).reset_index(drop = True))\n",
    "\n",
    "X_norm = X_less_norm_comb.rename(columns={0: 'national_inv', 1: 'lead_time', 2: 'in_transit_qty', \n",
    "                                 3: 'forecast_3_month', 4: 'sales_1_month', 5: 'sales_3_month', \n",
    "                                 6: 'min_bank' , 7: 'potential_issue', 8: 'pieces_past_due', \n",
    "                                 9: 'perf_6_month_avg', 10: 'local_bo_qty', 11: 'deck_risk', \n",
    "                                 12: 'oe_constraint', 13: 'ppap_risk', 14: 'stop_auto_buy', \n",
    "                                 15: 'rev_stop'})\n",
    "'''#X_less_norm_comb.info()\n",
    "#column = X.columns.values\n",
    "#print(column)\n",
    "#X_norm.info()\n",
    "\n",
    "#check = pd.DataFrame(X_norm['potential_issue'].unique())\n",
    "#print(check)\n",
    "\n",
    "X_norm = pd.Series(X_less_norm_comb)\n",
    "\n",
    "print('potential_issue', X_norm['potential_issue'].unique())\n",
    "print('/deck_risk', X_norm['deck_risk'].unique())\n",
    "print('/oe_constraint', X_norm['oe_constraint'].unique())\n",
    "print('/ppap_risk', X_norm['ppap_risk'].unique())\n",
    "print('/stop_auto_buy', X_norm['stop_auto_buy'].unique())\n",
    "print('/rev_stop', X_norm['rev_stop'].unique())\n",
    "print('/went_on_backorder', X_norm['went_on_backorder'].unique())\n",
    "\n",
    "potential_issue\n",
    "\n",
    "for col in X_norm:\n",
    "  print(X_norm[col].unique())'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split downsampled dataset into training and testing sets\n",
    "# Small sample to test pipelines\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_less, y_less, test_size = 0.2)\n",
    "# Full sample\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a classification model\n",
    "\n",
    "\n",
    "We are free to use any of the models that we learned in the past or we can use new models. Here is a pool of methods: \n",
    "\n",
    "### Pool of Anomaly Detection Methods (Discussed in M4)\n",
    "1. IsolationForest\n",
    "2. EllipticEnvelope\n",
    "3. LocalOutlierFactor\n",
    "4. OneClassSVM\n",
    "5. SGDOneClassSVM\n",
    "\n",
    "### Pool of Feature Selection Methods (Discussed in M3)\n",
    "\n",
    "1. VarianceThreshold\n",
    "1. SelectKBest with any scoring method (e.g, chi, f_classif, mutual_info_classif)\n",
    "1. SelectKPercentile\n",
    "3. SelectFpr, SelectFdr, or  SelectFwe\n",
    "1. GenericUnivariateSelect\n",
    "2. PCA\n",
    "3. Factor Analysis\n",
    "4. Variance Threshold\n",
    "5. RFE\n",
    "7. SelectFromModel\n",
    "\n",
    "\n",
    "### Classification Methods (Discussed in M1-M2\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. Logistic Regression\n",
    "4. Naive Bayes\n",
    "5. Linear SVC\n",
    "6. SVC with kernels\n",
    "7. KNeighborsClassifier\n",
    "8. GradientBoostingClassifier\n",
    "9. XGBClassifier\n",
    "10. LGBM Classifier\n",
    "\n",
    "\n",
    "\n",
    "It is difficult to fit an anomaly detection method in the sklearn pipeline without writing custom codes. For simplicity, we avoid fitting an anomaly detection method within a pipeline. So we can create the workflow in two steps. \n",
    "* Step I: fit an outlier with the training set\n",
    "* Step II: define a pipeline using a feature selection and a classification method. Then cross-validate this pipeline using the training data without outliers. \n",
    "* Note: if your smart sample is somewhat imbalanced, you might want to change the scoring method in GridSearchCV (see the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "\n",
    "\n",
    "Once we fit the pipeline with gridsearch, we identify the best model and give an unbiased evaluation using the test set that we created in Part II. For unbiased evaluation we report confusion matrix, precision, recall, f1-score, accuracy, and other measures if you like. \n",
    "\n",
    "**Optional: Those who are interested in writing custom codes for adding an outlier detection method into the sklearn pipeline, please follow this discussion [thread](https://stackoverflow.com/questions/52346725/can-i-add-outlier-detection-and-removal-to-scikit-learn-pipeline).**\n",
    "\n",
    "\n",
    "**Note:** <span style='background:yellow'>We will be using Grid Search to find the optimal parameters of the pipelines.</span>\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.feature_selection import (SelectKBest, VarianceThreshold, \n",
    "                                       SelectPercentile, chi2, f_classif, mutual_info_classif)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix \n",
    "from numpy import where\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import sklearn.feature_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  \n",
    "Add cells as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "# Construct local outlier factor\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Get labels from classifier to cull outliers\n",
    "lof_outliers = lof.fit_predict(X_train) == -1 # This should be scaled for LR, but I could not make it work\n",
    "\n",
    "X_lof = X_train[~lof_outliers]\n",
    "y_lof = y_train[~lof_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.524377   0.72889405 0.7490062         nan 0.524377\n",
      " 0.72889405 0.7490062         nan 0.524377   0.72889405 0.7490062\n",
      "        nan 0.524377   0.72895916 0.7490062         nan 0.524377\n",
      " 0.72895916 0.7490062         nan 0.524377   0.72895916 0.7490062\n",
      "        nan 0.524377   0.72895916 0.7490062         nan 0.524377\n",
      " 0.72895916 0.7490062         nan 0.524377   0.72895916 0.7490062\n",
      "        nan 0.524377   0.72895916 0.7490062         nan 0.524377\n",
      " 0.72895916 0.7490062         nan 0.524377   0.72895916 0.7490062\n",
      "        nan 0.524377   0.72895916 0.7490062         nan 0.524377\n",
      " 0.72895916 0.7490062         nan 0.524377   0.72895916 0.7490062 ]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "# Define pipeline\n",
    "pipe = Pipeline([\n",
    "    ('PCA', PCA()),\n",
    "    ('LR_model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'PCA__n_components': [0, 1, 2, 3],\n",
    "              'PCA__random_state':[17],\n",
    "              'LR_model__C': [0.001, 0.1, 1.0, 10, 100], \n",
    "              'LR_model__max_iter': [1000, 2500, 5000]\n",
    "              }\n",
    "\n",
    "# Use Grid Search to train Pipeline\n",
    "CV_log_reg = GridSearchCV(pipe, param_grid, n_jobs = 2, cv = 10)\n",
    "CV_log_reg_model = CV_log_reg.fit(X_lof, y_lof)\n",
    "#print(CV_log_reg.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      " Pipeline(steps=[('PCA', PCA(n_components=3, random_state=17)),\n",
      "                ('LR_model', LogisticRegression(C=0.001, max_iter=1000))])\n",
      "\n",
      "Confusion Matrix:\n",
      "      0    1\n",
      "0  144   86\n",
      "1   14  191\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.63      0.74       230\n",
      "           1       0.69      0.93      0.79       205\n",
      "\n",
      "    accuracy                           0.77       435\n",
      "   macro avg       0.80      0.78      0.77       435\n",
      "weighted avg       0.81      0.77      0.77       435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "'''# Show parameters of trained models and their rank\n",
    "pd.set_option(\"max_colwidth\", 80)\n",
    "CV_log_reg_df = pd.DataFrame(CV_log_reg.cv_results_)\n",
    "print(CV_log_reg_df[['params','rank_test_score']])'''\n",
    "\n",
    "# Evaluate best model using test data\n",
    "predicted_y = CV_log_reg.predict(X_test)\n",
    "\n",
    "'''# Show parameters of best model\n",
    "best_params = CV_log_reg.best_params_\n",
    "print('Best parameter:\\n',best_params)'''\n",
    "\n",
    "# Show best estimator\n",
    "best_estimator = CV_log_reg.best_estimator_\n",
    "print('Best estimator:\\n',best_estimator) \n",
    "\n",
    "# Display confusion matrix\n",
    "print('\\nConfusion Matrix:\\n',pd.DataFrame(confusion_matrix(y_test, predicted_y)))\n",
    "\n",
    "# Create classification report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, predicted_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "The best hyperparameters for the first pipeline were PCA with n_components of 3, and a logistic regression model with a C of 0.001 and a max of 1,000 iterations. The model had a weighted avg precision of 81%, recall of 77% and an f1-score of 77%. This means 81% of the time the model will correctly predict a product will go on backorder (FP) and 77% of all the times the model predicts a products will go on backorder it will be correct (FN). When interested in minimizing both false positives and false negatives, this models does so at 77%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/covariance/_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "# Construct envelope\n",
    "ee = EllipticEnvelope()\n",
    "# Fit data to envelope\n",
    "#envelope = env.fit(X_train_norm, y_train_norm)\n",
    "envelope = ee.fit(X_train, y_train)\n",
    "\n",
    "# Get labels from classifier to cull outliers\n",
    "env_outliers = envelope.predict(X_train) == -1\n",
    "\n",
    "# Re-slice X,y into a cleaned dataset with outliers excluded\n",
    "X_env = X_train[~env_outliers]\n",
    "y_env = y_train[~env_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.77736404 0.80804344 0.81442512 0.80806386 0.8170423  0.79656623\n",
      " 0.81887963 0.84131145 0.82469786 0.80223338 0.80104116 0.82654744\n",
      " 0.83426017 0.80742691 0.81565817 0.80167402 0.78621182 0.8061612\n",
      " 0.78633431 0.77090887        nan        nan        nan        nan\n",
      "        nan 0.77736404 0.81378818 0.8060877  0.80741875 0.79846889\n",
      " 0.79656623 0.82077005 0.82659644 0.80554058 0.81698106 0.80104116\n",
      " 0.81378409 0.82849094 0.8074065  0.79908542 0.80167402 0.78621182\n",
      " 0.80487914 0.78831455 0.774114          nan        nan        nan\n",
      "        nan        nan 0.77736404 0.81316348 0.8163482  0.80545484\n",
      " 0.79914666 0.79656623 0.81440879 0.82788257 0.84067451 0.80542218\n",
      " 0.80104116 0.81821819 0.82788257 0.80739833 0.78431733 0.80167402\n",
      " 0.78749388 0.80487914 0.77864609 0.78434183        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "#kb = SelectKBest()\n",
    "#rfc = RandomForestClassifier(random_state = 17)\n",
    "#fa = FactorAnalysis()\n",
    "#dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Define pipeline\n",
    "pipe2 = Pipeline(\n",
    "    [\n",
    "        #('scaler', StandardScaler()),\n",
    "        ('kbest', SelectKBest(mutual_info_classif)),\n",
    "        #('rfc_model', rfc)\n",
    "        #('fa', FactorAnalysis()),\n",
    "        ('dtc_model', DecisionTreeClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid2 = [\n",
    "    {\n",
    "        #'fa__n_components': [5, 20, 80, 120, 480],\n",
    "        'kbest__k': [1, 3, 5, 10, 15],\n",
    "        'dtc_model__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'dtc_model__max_leaf_nodes': [None, 15, 10, 5, 1],\n",
    "        'dtc_model__random_state': [17]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Use Grid Search to train Pipeline\n",
    "CV_dtc = GridSearchCV(pipe2, param_grid = param_grid2, n_jobs = 2, cv = 10)\n",
    "CV_dtc_model = CV_dtc.fit(X_env, y_env)\n",
    "#print(CV_dtc.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      " Pipeline(steps=[('kbest',\n",
      "                 SelectKBest(k=5,\n",
      "                             score_func=<function mutual_info_classif at 0x7f63b383a048>)),\n",
      "                ('dtc_model',\n",
      "                 DecisionTreeClassifier(max_features='auto', max_leaf_nodes=15,\n",
      "                                        random_state=17))])\n",
      "\n",
      "Confusion Matrix:\n",
      "      0    1\n",
      "0  139   91\n",
      "1   18  187\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.60      0.72       230\n",
      "           1       0.67      0.91      0.77       205\n",
      "\n",
      "    accuracy                           0.75       435\n",
      "   macro avg       0.78      0.76      0.75       435\n",
      "weighted avg       0.79      0.75      0.74       435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "'''# Show parameters of trained models and their rank\n",
    "pd.set_option(\"max_colwidth\", 80)\n",
    "CV_dtc_df = pd.DataFrame(CV_dtc.cv_results_)\n",
    "print(CV_dtc_df[['params','rank_test_score']])'''\n",
    "\n",
    "# Evaluate best model using test data\n",
    "predicted_y = CV_dtc.predict(X_test)\n",
    "\n",
    "'''# Show parameters of best model\n",
    "best_params = CV_dtc.best_params_\n",
    "print('Best parameter:\\n',best_params)'''\n",
    "\n",
    "# Show best estimator\n",
    "best_estimator = CV_dtc.best_estimator_\n",
    "print('Best estimator:\\n',best_estimator) \n",
    "\n",
    "# Display confusion matrix\n",
    "print('\\nConfusion Matrix:\\n',pd.DataFrame(confusion_matrix(y_test, predicted_y)))\n",
    "\n",
    "# Create classification report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, predicted_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "The best hyperparameters for the second pipeline were SelectKBest with k of 5, and a decision tree classifier model with auto max features and max leaf nodes of 15. The model had a weighted avg precision of 79%, recall of 75% and an f1-score of 74%. This means 79% of the time the model will correctly predict a product will go on backorder (FP) and 75% of all the times the model predicts a products will go on backorder it will be correct (FN). When interested in minimizing both false positives and false negatives, this model does so at 74%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "# Construct IsolationForest\n",
    "iso_forest = IsolationForest(n_estimators = 250)\n",
    "\n",
    "iso_outliers = iso_forest.fit(X_train, y_train)\n",
    "\n",
    "# Get labels from classifier to cull outliers\n",
    "iso_outliers = iso_forest.predict(X_train) == -1\n",
    "\n",
    "X_iso = X_train[~iso_outliers]\n",
    "y_iso = y_train[~iso_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "# Define pipeline\n",
    "pipe3 = Pipeline(\n",
    "    [\n",
    "        #('fa', FactorAnalysis()),\n",
    "        #('vt', VarianceThreshold()),\n",
    "        ('k_percentile', SelectPercentile()),\n",
    "        ('rfc_model', RandomForestClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid3 = [\n",
    "    {\n",
    "        #'fa__n_components': [5, 20, 80, 120, 480],\n",
    "        #'fa__random_state': [17],\n",
    "        #'vt__threshold': [0, 0.0001, 0.001, 0.01, 0.1],\n",
    "        'k_percentile__percentile': [1, 5, 10, 50, 75],\n",
    "        'rfc_model__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "        'rfc_model__max_depth': [None, 55, 30, 10, 1],\n",
    "        'rfc_model__n_estimators':[25, 50, 100, 150, 500]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Use Grid Search to train Pipeline\n",
    "CV_rfc = GridSearchCV(pipe3, param_grid = param_grid3, n_jobs = 2, cv = 5)\n",
    "CV_rfc_model = CV_rfc.fit(X_iso, y_iso)\n",
    "#print(CV_rfc.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('k_percentile', SelectPercentile(percentile=75)),\n",
      "                ('rfc_model',\n",
      "                 RandomForestClassifier(max_depth=55, n_estimators=500))])\n",
      "\n",
      "Confusion Matrix:\n",
      "      0    1\n",
      "0  206    6\n",
      "1    9  214\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       212\n",
      "           1       0.97      0.96      0.97       223\n",
      "\n",
      "    accuracy                           0.97       435\n",
      "   macro avg       0.97      0.97      0.97       435\n",
      "weighted avg       0.97      0.97      0.97       435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "'''# Show parameters of trained models and their rank\n",
    "pd.set_option(\"max_colwidth\", 80)\n",
    "CV_rfc_df = pd.DataFrame(CV_rfc.cv_results_)\n",
    "print(CV_rfc_df[['params','rank_test_score']])'''\n",
    "\n",
    "## Evaluate best model using test data\n",
    "# Make prediction using test data\n",
    "predicted_y = CV_rfc.predict(X_test)\n",
    "\n",
    "'''# Show parameters of best model\n",
    "best_params = CV_rfc.best_params_\n",
    "print('Best parameter:\\n',best_params)'''\n",
    "\n",
    "# Show best estimator\n",
    "best_estimator = CV_rfc.best_estimator_\n",
    "print('\\nBest estimator:\\n',best_estimator) \n",
    "\n",
    "# Display confusion matrix\n",
    "print('\\nConfusion Matrix:\\n',pd.DataFrame(confusion_matrix(y_test, predicted_y)))\n",
    "\n",
    "'''#Display accuracy score\n",
    "print('\\nAccuracy Score:\\n', pd.DataFrame(accuracy_score(y_test.actual_label.values, predicted_y.predicted_RF.values)))'''\n",
    "\n",
    "# Create classification report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, predicted_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# ---------------------------------------------\n",
    "The best hyperparameters for the third pipeline were k percentile with a percintile of 75, and a random forest classifier model with max features of square root and 150 estimators. The model had a weighted avg precision of 97%, recall of 97% and an f1-score of 97%. This means 97% of the time the model will correctly predict a product will go on backorder (FP) and 97% of all the times the model predicts a products will go on backorder it will be correct (FN). When interested in minimizing both false positives and false negatives, this models does so at 97%.\n",
    "\n",
    "##### NOTE: Would like to have plotted ROC curves #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare these three pipelines and discuss your findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "The third pipeline scored better in each category. No matter whether minimizing false positives (precision), minimizing false negatives (recall), or minimizing any false predictions (f-1 score) is of the utmost importance for this business, the third pipline is the best one to choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/pipeline-v3.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle the best pipeline\n",
    "joblib.dump([pipe3, CV_rfc, CV_rfc_model], 'data/pipeline-v3.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have made a few commits so far of this project.  \n",
    "**Definitely make a commit of the notebook now!**  \n",
    "Comment should be: `Final Project, Checkpoint - Pipelines done`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
