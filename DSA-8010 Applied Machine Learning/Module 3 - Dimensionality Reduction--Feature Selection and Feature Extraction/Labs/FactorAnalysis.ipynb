{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Factor analysis\n",
    "\n",
    "In this lab you will learn about **Factor Analysis** (FA),\n",
    "which is a linear factor model that not only assumes observables are a linear combination of factors\n",
    "(or latent variables) plus noise, but also that they follow Gaussian distribution.\n",
    "In addition, observed variables are assumed to be conditionally independent, given latent variables.\n",
    "\n",
    "Some key aspects to focus on:\n",
    "+ Fewer factors than original features in data space.\n",
    "+ Different types of methods and solutions.\n",
    "+ More elaborate framework than principal component analysis.\n",
    "\n",
    "For this session, we are going to use **red wine quality** dataset for factor analysis and\n",
    "transform its data space into feature space with 5 factors.\n",
    "\n",
    "sklearn API reference:\n",
    "\n",
    "+ [sklearn.decomposition.FactorAnalysis](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html)\n",
    "\n",
    "**Note:** Previously you saw Factor Analysis in the 8610 (Stat/Math) course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/wine-quality/winequality-red.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET, sep=';').sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "X = np.array(dataset.iloc[:, :-1])\n",
    "y = np.array(dataset.quality)\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor analysis with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(n_components=5)\n",
    "X_features = fa.fit_transform(X)\n",
    "print('Features shape', X_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of the factor model\n",
    "\n",
    "Factor analysis essentially proposes the following to explain the structure of the observables:\n",
    "\n",
    "$$ X - \\mu = LF + \\varepsilon $$\n",
    "\n",
    "+ L: Factor loadings\n",
    "+ F: Features\n",
    "\n",
    "That is to assume observables are a linear combination of latent variables plus noise.\n",
    "And this is an estimation problem that usually takes some numerical computation to solve iteratively.\n",
    "\n",
    "In practice, to solve factor analysis, the **goal** would be to find estimates of factor loadings **L** and specific variances **Ψ**, such that:\n",
    "\n",
    "$$ cov(X) = LL^T + cov(\\varepsilon) = LL^T + \\Psi $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor loadings\n",
    "\n",
    "The factor loadings is the matrix **L** would take latent variables and transform them to observables **X** minus its mean and noise.\n",
    "The following cell prints one found by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FactorLoadings(components, n_components=5):\n",
    "    \"\"\"This functions puts a frame on the loadings matrix for prettified printing\"\"\"\n",
    "    return pd.DataFrame(components.T,\n",
    "        columns = ['Factor {}'.format(i+1) for i in range(n_components)],\n",
    "        index = dataset.columns[:-1])\n",
    "\n",
    "FactorLoadings(fa.components_, n_components=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific variances\n",
    "\n",
    "The specific variances matrix **Ψ** is a _diagonal matrix_ representing the variances of \n",
    "noise in the model with the following elements on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.noise_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of data space\n",
    "\n",
    "The factor analysis models the observables **X** as a linear combination of factors plus noise.\n",
    "Therefore, it should be insteresting to reconstruct data space with some solution appropiate for the formulation of factor analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Factors shape', fa.components_.shape)\n",
    "noise = np.random.multivariate_normal(np.mean(X, axis = 0), np.diag(fa.noise_variance_), X.shape[0])\n",
    "X_reconstructed = np.dot(X_features, fa.components_) + noise\n",
    "print('Reconstructed dataset shape', X_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows a reconstructed dataset which is an approximation of original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_reconstructed, columns = dataset.columns[:-1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the original dataset for comparison.\n",
    "They **could appear to be very different**, although still following some general pattern,\n",
    "because random noise was just introduced,\n",
    "but this aims to demonstrate the connection between data space and feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:5, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify covariance structure of FA\n",
    "\n",
    "A more meaningful thing to try than restructing data space could be verifying its covariance structure,\n",
    "because unlike the previous example, we don't have to re-introduce noise which was lost during factor analysis.\n",
    "\n",
    "In practice, a proper solution to FA is usually verfied by plugging into the claim 1 below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim 1:\n",
    "\n",
    "$$ cov(X) = LL^T + \\Psi $$\n",
    "\n",
    "+ L: Factor loadings\n",
    "+ Ψ: Specific variance / noise variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = scale(X, with_std = False)\n",
    "\n",
    "print(np.allclose(\n",
    "    np.dot(X_centered.T, X_centered) / X.shape[0],                # left hand side: covariance matrix of X\n",
    "    np.dot(fa.components_.T, fa.components_) + np.diag(fa.noise_variance_)   # right hand side\n",
    "))\n",
    "\n",
    "print(np.isclose(\n",
    "    np.dot(X_centered.T, X_centered) / X.shape[0],                # left hand side: covariance matrix of X\n",
    "    np.dot(fa.components_.T, fa.components_) + np.diag(fa.noise_variance_),  # right hand side\n",
    "atol=1e-2, rtol=1e-1).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this factor analysis solution provided by sklearn wasn't very precise, it's still close and useful.\n",
    "\n",
    "The following cell compares our calculations with those provided by numpy and sklearn packages.\n",
    "It turns out that the computation of **left_hand_side** and **right_hand_side** are accurate to definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(\n",
    "    np.dot(X_centered.T, X_centered) / X.shape[0],                # left hand side: covariance matrix of X\n",
    "    np.cov(X, rowvar = False, bias = True)                        # covariance matrix by numpy\n",
    "))\n",
    "\n",
    "print(np.allclose(\n",
    "    np.dot(fa.components_.T, fa.components_) + np.diag(fa.noise_variance_),  # right hand side\n",
    "    fa.get_covariance()                                           # covariance matrix by sklearn\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim 2:\n",
    "\n",
    "$$ cov(X, F) = L$$ \n",
    "\n",
    "+ L: Factor loadings\n",
    "+ F: Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(\n",
    "    np.mean(X[..., np.newaxis] * np.expand_dims(X_features, 1), axis = 0), # left hand side\n",
    "    fa.components_.T,                                                      # right hand side\n",
    "rtol = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The principal component solution\n",
    "\n",
    "Factor analysis provides a latent linear model to explain the observables **x**, \n",
    "which serves as a valuable insight towards feature extraction.\n",
    "However, different types of methods have been proposed for solving factor analysis, including the **principal component method** and the **maximum likelihood method**.\n",
    "\n",
    "Now, we plug principal components into covariance structure of factor analysis\n",
    "to verify this is one of its solutions. \n",
    "This also demonstrates the relation between FA and PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "PCA_features = pca.fit_transform(X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify claim 1\n",
    "\n",
    "$$cov(X) = L L^T + \\Psi$$\n",
    "\n",
    "+ L: Factor loadings - provided by spectral decomposition\n",
    "+ Ψ: Noise variance - set to 0 becaues PCA doesn't model noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isclose(\n",
    "    np.dot(X_centered.T, X_centered) / X.shape[0],      # left hand side: covariance matrix of X\n",
    "    sum(eigenvalue*np.outer(eigenvector,eigenvector)    # right hand side: spectral decomposition\n",
    "        for eigenvalue, eigenvector in zip(pca.explained_variance_, pca.components_)),\n",
    "atol=1e-2, rtol=1e-1).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: PCA could be considered a special case to FA.\n",
    "\n",
    "## Factor loadings\n",
    "\n",
    "The following is the factor loadings offered by PCA. This is a corollary from spectral decomposition in its additive form. \n",
    "Please refer to [_spectral decomposition_](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix) for further information if interested.\n",
    "\n",
    "$$cov(X)=\\sum \\lambda_i q_i q_i^T = LL^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FactorLoadings(np.vstack([np.sqrt(eigenvalue)*eigenvector\n",
    "    for eigenvalue, eigenvector in zip(pca.explained_variance_, pca.components_)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor analysis vs principal component analysis\n",
    "\n",
    "+ FA imposes a structure with fixed number of factors; PCA analyzes the eigenstructure of data and provides principal components in descreasing order of importance.\n",
    "+ FA focuses on interpretation of data; PCA focuses on maximizing variances.\n",
    "+ FA provides a model that needs estimation techniques to solve; PCA is a well-defined algorithm with unique solution.\n",
    "+ FA and PCA both assume the linear structure of the data and utilize similar set of mathematical tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scree plot\n",
    "\n",
    "This plots variances (y-axis) against components (x-axis).\n",
    "It helps us to decide on number of principal components to be retained, although this is subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = np.flip(np.sort(np.sum(fa.components_**2, axis=1)), axis=0)\n",
    "x_ticks = np.arange(len(fa.components_))+1\n",
    "plt.xticks(x_ticks) # this enforces integers on the x-axis\n",
    "plt.plot(x_ticks, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, you could also plot the explained variance ratio.\n",
    "FA should not have total explained variance ratio equal to 1 because of noise variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = explained_variance/(np.sum(explained_variance)+np.sum(fa.noise_variance_))\n",
    "plt.xticks(x_ticks) # this enforces integers on the x-axis\n",
    "plt.plot(x_ticks, explained_variance_ratio)\n",
    "print('total expained variance ratio', np.sum(explained_variance_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab we learned about:\n",
    "+ Apply FA to a dataset for feature extraction.\n",
    "+ Reconstruction of original dataset from FA.\n",
    "+ Convariance structure of FA.\n",
    "+ Comparing FA and PCA.\n",
    "+ Scree plot of FA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
