{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validate $\\rightarrow$ Train, Test\n",
    "\n",
    "In this exercise, you will perform empirical comparison of the results of a ten-fold cross validated model with a fully trained model.\n",
    "\n",
    "## Notes and Guidelines\n",
    "* Read a dataset from disk and use it for a classification task.\n",
    "* Construct a Gaussian Naive Bayes classifier and fit it to the phoneme dataset provided.\n",
    "* Save and re-load a trained classifier.\n",
    "* Compare K-fold cross-validation scores with the success rate of a fully-trained model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "* Dataset acquired from [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=105), an excellent resource for finding 'toy' datasets (and a few more serious ones).\n",
    "    * A description of the dataset is provided at the above link - **read it.**\n",
    "    * Excerpt: \n",
    "    *The aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1).\n",
    "    The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1.\n",
    "    The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.*\n",
    "    \n",
    "* It is not necessary to fully understand the nature or context of the values in the dataset - only that there are five columns of input (featural) data and one column of output (class) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imports and dataset inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# <import necessary modules> \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# locate dataset\n",
    "DATASET = '/dsa/data/all_datasets/phoneme.csv'  # phoneme classification dataset\n",
    "assert os.path.exists(DATASET)  # check if the file actually exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing DataFrame from raw dataset\n",
    "\n",
    "<span style=\"background:yellow\">**Note**</span>: Variable `dataset` should be used for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (5404, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(DATASET, header=0).sample(frac=1)\n",
    "\n",
    "# verify dataset shape\n",
    "print(\"Dataset shape: \", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aa</th>\n",
       "      <th>Ao</th>\n",
       "      <th>Dcl</th>\n",
       "      <th>Iy</th>\n",
       "      <th>Sh</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.185</td>\n",
       "      <td>1.416</td>\n",
       "      <td>2.055</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>0.249</td>\n",
       "      <td>1.876</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>0.249</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.933</td>\n",
       "      <td>2.165</td>\n",
       "      <td>-1.034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>2.514</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Aa     Ao    Dcl     Iy     Sh  Class\n",
       "1670  0.185  1.416  2.055  0.872  0.000      0\n",
       "2998  0.157  0.642  0.459  0.761  0.000      1\n",
       "4251  0.249  1.876  0.914  0.379  0.000      0\n",
       "3117  0.249  0.569  0.933  2.165 -1.034      1\n",
       "1636  2.514 -0.238  0.103  0.089  0.090      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first few lines of the dataset\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and test sets\n",
    "\n",
    "Split the datasets into training (80%) and testing (20%) sets. \n",
    "\n",
    "The below is only necessary if you are interested in visualizing\n",
    "the data or providing neatly-labeled output within the program.\n",
    "\n",
    "```python\n",
    "# extract labels from column headers\n",
    "phonemes = dataset.columns[0:5].tolist()  # Feature labels\n",
    "labels = {0: 'Nasal', 1: 'Oral'}  # Class labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from column headers\n",
    "phonemes = dataset.columns[0:5].tolist()  # Feature labels\n",
    "labels = {0: 'Nasal', 1: 'Oral'}  # Class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and class data from primary data frame\n",
    "X = dataset.loc[:,\"Aa\":\"Sh\"]    # include all the columns except the last one\n",
    "y = dataset.loc[:,\"Class\"]   # last col (survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Aa     Ao    Dcl     Iy     Sh\n",
      "1670  0.185  1.416  2.055  0.872  0.000\n",
      "2998  0.157  0.642  0.459  0.761  0.000\n",
      "4251  0.249  1.876  0.914  0.379  0.000\n",
      "3117  0.249  0.569  0.933  2.165 -1.034\n",
      "1636  2.514 -0.238  0.103  0.089  0.090\n",
      "...     ...    ...    ...    ...    ...\n",
      "1956  0.540  3.144 -0.665 -0.261  0.000\n",
      "3654  0.212  0.746  0.905 -0.393  1.210\n",
      "655   0.124  0.426  0.948  0.710  0.000\n",
      "2520  0.651  2.527  0.904  0.336  0.000\n",
      "3313  0.222  0.433  0.684  1.743  0.000\n",
      "\n",
      "[5404 rows x 5 columns]\n",
      "1670    0\n",
      "2998    1\n",
      "4251    0\n",
      "3117    1\n",
      "1636    0\n",
      "       ..\n",
      "1956    0\n",
      "3654    1\n",
      "655     1\n",
      "2520    0\n",
      "3313    1\n",
      "Name: Class, Length: 5404, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes (X, y):  (3782, 5) (3782,)\n",
      "Testing shapes (X, y):  (1622, 5) (1622,)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Training shapes (X, y): \", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the classifier and running automated cross-validation\n",
    "\n",
    "* Run a 10-fold cross validation with `GaussianNB` classifier\n",
    "* Print the accuracy scores for these 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78100264 0.77572559 0.76455026 0.73015873 0.76719577 0.77777778\n",
      " 0.76984127 0.75925926 0.74338624 0.76984127]\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line (Question #E101)\n",
    "# --------------------------\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# perform 10-fold *automated* cross-validation on the data\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv = 10)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier and pickling to disk\n",
    "* Learn the model with all the training instances and store to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      1139\n",
      "           1       0.57      0.72      0.64       483\n",
      "\n",
      "    accuracy                           0.76      1622\n",
      "   macro avg       0.72      0.75      0.73      1622\n",
      "weighted avg       0.78      0.76      0.76      1622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line (Question #E102)\n",
    "# --------------------------\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# re-fit a model to the data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test model performance\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GaussianPhonemes.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle model to disk\n",
    "joblib.dump(classifier, 'GaussianPhonemes.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickling the model and making predictions\n",
    "\n",
    "* Load the saved model \n",
    "* Make predictions for the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vs. output shape:\n",
      "(1622, 5) (1622,)\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line (Question #E103)\n",
    "# --------------------------\n",
    "# load pickled model\n",
    "loaded_model = joblib.load('GaussianPhonemes.pkl')\n",
    "\n",
    "# make predictions with freshly loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# verify input and output shape are appropriate\n",
    "print(\"Input vs. output shape:\")\n",
    "print(X_test.shape, y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing final performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct guesses: 1226\n",
      "Incorrect guesses: 396\n",
      "Percent correct: 75.58569667077681\n",
      "Percent cross-validation score (10 folds, average): 76.38738814200556\n"
     ]
    }
   ],
   "source": [
    "# tally up right + wrong 'guesses' by model\n",
    "true, false = 0, 0\n",
    "for i, j in zip(y_test, y_pred):\n",
    "    # print(i, j)\n",
    "    if i == j:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "\n",
    "# report results numerically and by percentage\n",
    "true_percent = true / (true + false) * 100\n",
    "print(\"Correct guesses: \" + str(true) + \"\\nIncorrect guesses: \" + str(false))\n",
    "print(\"Percent correct: \" + str(true_percent))\n",
    "\n",
    "# compare to average of cross-validation scores\n",
    "avg_cv = np.sum(scores) / len(scores) * 100\n",
    "print(\"Percent cross-validation score (10 folds, average): \" + str(avg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure performance using Scikit Learn modules \n",
    "\n",
    "Compute and display the following:\n",
    " 1. Compute Confusion Matrix\n",
    " 1. Accuracy\n",
    " 1. Precision\n",
    " 1. Recall\n",
    " 1. $F_1$-Score\n",
    " \n",
    "Add additional cells if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[876 263]\n",
      " [133 350]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      1139\n",
      "           1       0.57      0.72      0.64       483\n",
      "\n",
      "    accuracy                           0.76      1622\n",
      "   macro avg       0.72      0.75      0.73      1622\n",
      "weighted avg       0.78      0.76      0.76      1622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line  (Question #E104)\n",
    "# --------------------------\n",
    "# create confustion matrix\n",
    "print(\"Confusion matrix:\\n\",confusion_matrix(y_test, loaded_model.predict(X_test)))\n",
    "\n",
    "# print loaded model's performance\n",
    "print(\"\\nClassification report:\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions ?\n",
    "\n",
    "How did your trained model perform relative to your expectations based on the cross-validation?\n",
    "Provide your answer in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add your answer below this comment  (Question #E105)\n",
    "# -----------------------------------\n",
    "The trained model's correct percentage and CV score are pretty close suggesting the trained model is performing well; however, a look at the distribution of the errors would be useful to get a better idea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!  Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
