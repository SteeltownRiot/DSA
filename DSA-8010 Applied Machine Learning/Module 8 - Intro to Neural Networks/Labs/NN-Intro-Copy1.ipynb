{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial neuron\n",
    "\n",
    "Recall the concept of a [neuron](https://en.wikipedia.org/wiki/Artificial_neuron) based on its mathematical formula.\n",
    "\n",
    "$$ y_k = \\varphi \\left( \\sum_{j=0}^{m}{w_{kj}x_j} +b_k \\right) $$\n",
    "\n",
    "This is a simple **linear** neuron. If you look closely, you will see the formula for multiple linear regression (if $\\varphi$ is removed)! If $\\varphi$ is a sigmoid funciton then it becomes the formula for losistic regression. \n",
    "\n",
    "PyTorch, as well as other NN packages, support numerous types of neurons. Typically, neurons are composed into layers, and a single layer has only a single type of neuron.\n",
    "\n",
    "In this lab, we devlop linear regression and logistic regression models with neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale, LabelBinarizer, StandardScaler, Normalizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Multiple Regression Model using Neural Network\n",
    "\n",
    "Let's explore the (Boston housing dataset apparently has an ethical problem) Californai housing dataset, which is used in a regression setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = datasets.load_boston()\n",
    "dataset = datasets.fetch_california_housing()\n",
    "\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Price  \n",
       "0    -122.23  4.526  \n",
       "1    -122.22  3.585  \n",
       "2    -122.24  3.521  \n",
       "3    -122.25  3.413  \n",
       "4    -122.25  3.422  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['Price'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>1.153956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude         Price  \n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704      2.068558  \n",
       "std       10.386050      2.135952      2.003532      1.153956  \n",
       "min        0.692308     32.540000   -124.350000      0.149990  \n",
       "25%        2.429741     33.930000   -121.800000      1.196000  \n",
       "50%        2.818116     34.260000   -118.490000      1.797000  \n",
       "75%        3.282261     37.710000   -118.010000      2.647250  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      "MedInc        20640 non-null float64\n",
      "HouseAge      20640 non-null float64\n",
      "AveRooms      20640 non-null float64\n",
      "AveBedrms     20640 non-null float64\n",
      "Population    20640 non-null float64\n",
      "AveOccup      20640 non-null float64\n",
      "Latitude      20640 non-null float64\n",
      "Longitude     20640 non-null float64\n",
      "Price         20640 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization/Normalization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.117437</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.922314</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.108501</td>\n",
       "      <td>-0.350107</td>\n",
       "      <td>0.012964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>-0.050829</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014092</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.073493</td>\n",
       "      <td>-0.237353</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.090448</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.970573</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>-0.212639</td>\n",
       "      <td>0.005936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.089393</td>\n",
       "      <td>0.010799</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.971286</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>-0.210159</td>\n",
       "      <td>0.005883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  0.023846  0.117437  0.020005   0.002933    0.922314  0.007320  0.108501   \n",
       "1  0.003452  0.008734  0.002594   0.000404    0.998534  0.000877  0.015745   \n",
       "2  0.014092  0.100968  0.016093   0.002084    0.963083  0.005441  0.073493   \n",
       "3  0.009815  0.090448  0.010119   0.001866    0.970573  0.004432  0.065835   \n",
       "4  0.006612  0.089393  0.010799   0.001858    0.971286  0.003750  0.065068   \n",
       "\n",
       "   Longitude     Price  \n",
       "0  -0.350107  0.012964  \n",
       "1  -0.050829  0.001491  \n",
       "2  -0.237353  0.006837  \n",
       "3  -0.212639  0.005936  \n",
       "4  -0.210159  0.005883  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = Normalizer()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(data_scaled, columns=list(dataset.feature_names) + ['Price'])\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('Price', axis=1).to_numpy()\n",
    "y = df_scaled['Price'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a neural network\n",
    "\n",
    "Now we will construct a basic Neural Network with\n",
    " * One hidden layer fed by 13 input values (as there are 13 features)\n",
    " * One output layer \n",
    " \n",
    "##### Note: The summary will show that we have 16 total learnable parameters:\n",
    "  * 14 for the hidden layer (13 feature values and bias)\n",
    "  * 1 for the output layer (Hidden ($H_0$) and without bias) \n",
    "  \n",
    "\n",
    "<figure>\n",
    "  <img src=\"../images/reg_as_nn.jpg\" width=600 height=400 alt=\"figure alt text\">\n",
    "  <figcaption>\n",
    "      <b>Fig. A neural network for solving muliple regression problem.</b> <!-- can also use <div>, <p>, etc. tags within <figcaption> -->\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary pytorch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "\n",
    "One way to define a neural network in PyTorch is to subclass the `nn.Module` class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        D_in: number of input\n",
    "        H: number of nurons in the hidden layer\n",
    "        D_out: number of output\n",
    "        \"\"\"\n",
    "        super(MyRegNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(D_in, H) # input to hidden layer\n",
    "        self.layer2 = nn.Linear(H, D_out, bias=False) # input to hidden layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_pred = self.layer1(x)        # h = dot(input,w1) \n",
    "        y_pred = self.layer2(h_pred)   \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an instance of the network class we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a network with 13 inputs to 1 hidden neurons to one output neuron \n",
    "\n",
    "D_in, H, D_out = X_train.shape[1], 1, 1    \n",
    "\n",
    "net = MyRegNN(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize this model using `summary` function from `torchsummary` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /opt/conda/lib/python3.7/site-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]               9\n",
      "            Linear-2                    [-1, 1]               1\n",
      "================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer has 9 parameters to be learned: 8 input has 8 coefficients and the intercept b_0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.SmoothL1Loss()     # Smooth L1 Loss (Huber Loss)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.3)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Before training the model, we need to convert the pandas/numpy datasets to pytorch's tensor data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors from the train/test set\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better iteration over the train/test sets, there are two handy methods: TensorDataset and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5  # it is possible to feed more than one istances to the model. \n",
    "# These set of instances is called batch. For simplicity, let's keep one instance per batch\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the mdoel with 100 epochs. The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. Within an epoch each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. \n",
    "\n",
    "Note: For simplicity we are skipping k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Total Loss: 3.06682 | Avg Loss: 0.00087\n",
      "Epoch 005: | Total Loss: 0.16502 | Avg Loss: 0.00005\n",
      "Epoch 010: | Total Loss: 0.13566 | Avg Loss: 0.00004\n",
      "Epoch 015: | Total Loss: 0.11498 | Avg Loss: 0.00003\n",
      "Epoch 020: | Total Loss: 0.10028 | Avg Loss: 0.00003\n",
      "Epoch 025: | Total Loss: 0.08971 | Avg Loss: 0.00003\n",
      "Epoch 030: | Total Loss: 0.08203 | Avg Loss: 0.00002\n",
      "Epoch 035: | Total Loss: 0.07641 | Avg Loss: 0.00002\n",
      "Epoch 040: | Total Loss: 0.07219 | Avg Loss: 0.00002\n",
      "Epoch 045: | Total Loss: 0.06904 | Avg Loss: 0.00002\n",
      "Epoch 050: | Total Loss: 0.06658 | Avg Loss: 0.00002\n",
      "Epoch 055: | Total Loss: 0.06465 | Avg Loss: 0.00002\n",
      "Epoch 060: | Total Loss: 0.06312 | Avg Loss: 0.00002\n",
      "Epoch 065: | Total Loss: 0.06184 | Avg Loss: 0.00002\n",
      "Epoch 070: | Total Loss: 0.06076 | Avg Loss: 0.00002\n",
      "Epoch 075: | Total Loss: 0.05983 | Avg Loss: 0.00002\n",
      "Epoch 080: | Total Loss: 0.05900 | Avg Loss: 0.00002\n",
      "Epoch 085: | Total Loss: 0.05826 | Avg Loss: 0.00002\n",
      "Epoch 090: | Total Loss: 0.05757 | Avg Loss: 0.00002\n",
      "Epoch 095: | Total Loss: 0.05693 | Avg Loss: 0.00002\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100  # In each epoch, the model iterate over all the instances \n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = net(x)        # Forward pass: get the network output for this instance\n",
    "        l = loss(output, y)    # estimate error for this instance\n",
    "        epoch_loss += l.item() # Aggregate error\n",
    "        optimizer.zero_grad()  # As backward method accumulates gradient, we need to set it to 0\n",
    "        l.backward()           # Backward pass: Estimate gradient \n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%5)==0:\n",
    "        print(f'Epoch {epoch+0:03}: | Total Loss: {epoch_loss:.5f} | Avg Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()  # notify all the layers that we are in eval mode\n",
    "\n",
    "with torch.no_grad(): \n",
    "    y_test_pred = net(X_test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -3.1266068756788705\n",
      "MSE:3.2643763011573e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(f\"R^2: {r2_score(y_test, y_test_pred.numpy())}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test, y_test_pred.numpy())}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of MSE and R^2, the neural network performed better than the baseline which predicts mean as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Logistic Regression Model using Neural Network\n",
    "\n",
    "For this lab, we will use sklearn breast cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['class'] = cancer.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization/Normalization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.889462</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.055988</td>\n",
       "      <td>0.558619</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>0.824026</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.572276</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.072545</td>\n",
       "      <td>0.812984</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.110899</td>\n",
       "      <td>0.551922</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037881</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.811515</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.631774</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.767189</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.007925      0.004573        0.054099   0.440986         0.000052   \n",
       "1     0.008666      0.007486        0.055988   0.558619         0.000036   \n",
       "2     0.009367      0.010109        0.061842   0.572276         0.000052   \n",
       "3     0.016325      0.029133        0.110899   0.551922         0.000204   \n",
       "4     0.009883      0.006985        0.065808   0.631774         0.000049   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.000122        0.000132             0.000065       0.000107   \n",
       "1          0.000033        0.000037             0.000030       0.000076   \n",
       "2          0.000076        0.000094             0.000061       0.000098   \n",
       "3          0.000406        0.000345             0.000150       0.000371   \n",
       "4          0.000065        0.000096             0.000051       0.000088   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.000035  ...       0.007635         0.081325    0.889462   \n",
       "1                0.000024  ...       0.009862         0.066899    0.824026   \n",
       "2                0.000029  ...       0.012145         0.072545    0.812984   \n",
       "3                0.000139  ...       0.037881         0.141333    0.811515   \n",
       "4                0.000029  ...       0.008120         0.074137    0.767189   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.000071           0.000293         0.000314              0.000117   \n",
       "1          0.000052           0.000079         0.000102              0.000078   \n",
       "2          0.000069           0.000202         0.000214              0.000116   \n",
       "3          0.000300           0.001238         0.000982              0.000368   \n",
       "4          0.000067           0.000100         0.000195              0.000079   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0        0.000203                 0.000052      0  \n",
       "1        0.000116                 0.000038      0  \n",
       "2        0.000172                 0.000042      0  \n",
       "3        0.000949                 0.000247      0  \n",
       "4        0.000115                 0.000037      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('class', axis=1).to_numpy()\n",
    "y = df['class'].to_numpy()\n",
    "\n",
    "scaler = Normalizer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=list(cancer.feature_names))\n",
    "df_scaled['class'] = y\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df_scaled['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a neural network\n",
    "\n",
    "Now we will construct a basic Neural Network with\n",
    " * One hidden layer fed by 30 input values (as there are 30 features)\n",
    " * One output layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogitNN(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        D_in: number of input\n",
    "        \"\"\"\n",
    "        super(MyLogitNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(D_in, H) # input to hidden layer\n",
    "        self.layer2 = nn.Linear(H, D_out, bias=False) # input to hidden layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_pred = self.layer1(x)        \n",
    "        y_pred = torch.sigmoid(self.layer2(h_pred))   \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an instance of the network class we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a network with 13 inputs to 1 hidden neurons to one output neuron \n",
    "\n",
    "D_in, H, D_out = X_train.shape[1], 1, 1    \n",
    "\n",
    "net = MyLogitNN(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize this model using `summary` function from `torchsummary` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]              31\n",
      "            Linear-2                    [-1, 1]               1\n",
      "================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.MSELoss()   \n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.3)  \n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Before training the model, we need to convert the pandas/numpy datasets to pytorch's tensor data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors from the train/test set\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better iteration over the train/test sets, there are two handy methods: TensorDataset and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5  # it is possible to feed more than one istances to the model. \n",
    "# These set of instances is called batch. For simplicity, let's keep one instance per batch\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the mdoel with 100 epochs. The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. Within an epoch each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. \n",
    "\n",
    "Note: For simplicity we are skipping k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Total Loss: 64.67423 | Avg Loss: 0.66674\n",
      "Epoch 005: | Total Loss: 64.73846 | Avg Loss: 0.66741\n",
      "Epoch 010: | Total Loss: 64.73683 | Avg Loss: 0.66739\n",
      "Epoch 015: | Total Loss: 64.66881 | Avg Loss: 0.66669\n",
      "Epoch 020: | Total Loss: 64.66696 | Avg Loss: 0.66667\n",
      "Epoch 025: | Total Loss: 64.66525 | Avg Loss: 0.66665\n",
      "Epoch 030: | Total Loss: 64.66334 | Avg Loss: 0.66663\n",
      "Epoch 035: | Total Loss: 64.72757 | Avg Loss: 0.66729\n",
      "Epoch 040: | Total Loss: 64.72577 | Avg Loss: 0.66728\n",
      "Epoch 045: | Total Loss: 64.72389 | Avg Loss: 0.66726\n",
      "Epoch 050: | Total Loss: 64.65639 | Avg Loss: 0.66656\n",
      "Epoch 055: | Total Loss: 64.58883 | Avg Loss: 0.66586\n",
      "Epoch 060: | Total Loss: 64.71857 | Avg Loss: 0.66720\n",
      "Epoch 065: | Total Loss: 64.65112 | Avg Loss: 0.66651\n",
      "Epoch 070: | Total Loss: 64.64934 | Avg Loss: 0.66649\n",
      "Epoch 075: | Total Loss: 64.71316 | Avg Loss: 0.66715\n",
      "Epoch 080: | Total Loss: 64.64605 | Avg Loss: 0.66645\n",
      "Epoch 085: | Total Loss: 64.57871 | Avg Loss: 0.66576\n",
      "Epoch 090: | Total Loss: 64.64244 | Avg Loss: 0.66642\n",
      "Epoch 095: | Total Loss: 64.57542 | Avg Loss: 0.66573\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100  # In each epoch, the model iterate over all the instances \n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = net(x)        # Forward pass: get the network output for this instance\n",
    "        l = loss(output, y)    # estimate error for this instance\n",
    "        epoch_loss += l.item() # Aggregate error\n",
    "        optimizer.zero_grad()  # As backward method accumulates gradient, we need to set it to 0\n",
    "        l.backward()           # Backward pass: Estimate gradient \n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%5)==0:\n",
    "        print(f'Epoch {epoch+0:03}: | Total Loss: {epoch_loss:.5f} | Avg Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4908],\n",
       "        [0.4897],\n",
       "        [0.4903],\n",
       "        [0.4904],\n",
       "        [0.4910]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()  # notify all the layers that we are in eval mode\n",
    "\n",
    "with torch.no_grad(): \n",
    "    y_test_pred = net(X_test_tensor)\n",
    "    \n",
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = torch.round(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[26  0]\n",
      " [60  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46        26\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.30        86\n",
      "   macro avg       0.15      0.50      0.23        86\n",
      "weighted avg       0.09      0.30      0.14        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_test_pred_class.numpy())}\")\n",
    "print(f\"\\nClassification Report:\\n {classification_report(y_test, y_test_pred_class.numpy())}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we learned a step-by-step process for developing neural networks for solving regression and classification problems. These are elementary neural networks, but the process is similar even if our network architecture has more layers/neurons.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PyTorch API and helpful links\n",
    "\n",
    " * Layers: https://pytorch.org/docs/stable/nn.html\n",
    " * Loss / Loss Functions : [link1](https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7) [link2](https://neptune.ai/blog/pytorch-loss-functions)\n",
    " * Optimizers (learning algorithm) : https://pytorch.org/docs/stable/optim.html\n",
    " * Neuron Activation Functions : https://towardsdatascience.com/understanding-pytorch-activation-functions-the-maths-and-algorithms-part-1-7d8ade494cee\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please restart the kernel and clear all output, then play around with parameters or add cells and create additional notebooks\n",
    "\n",
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
