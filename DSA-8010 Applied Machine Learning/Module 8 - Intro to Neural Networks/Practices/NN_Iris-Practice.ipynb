{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Iris with Neural Networks\n",
    "\n",
    "In this session, you will create a Multilayer Perceptron (MLP) model to practice on the Iris dataset, to get more familiarized with PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some initial library loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale, LabelEncoder, StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features in this dataset\n",
    "print('features', iris.feature_names)\n",
    "\n",
    "# Target classes of this 3-class prediction problem.\n",
    "print('targets', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Assign features and the target to variables X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P01)\n",
    "# ----------------------------------\n",
    "\n",
    "X = <placeholder>\n",
    "y = <placeholder>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a little more inspection\n",
    "\n",
    "Is `X` a pandas dataframe or a numpy array? What kind of data does it contain? Let's run some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('type', type(X))\n",
    "print('shape', X.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify to make that more readable.\n",
    "\n",
    "for stat, val in stats.describe(X)._asdict().items():\n",
    "    if stat!='minmax':\n",
    "        print('{:<10}: {}'.format(stat, val))\n",
    "    else:\n",
    "        print('{:<10}: {}'.format('min', val[0]))\n",
    "        print('{:<10}: {}'.format('max', val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print('type: ', type(y))\n",
    "print('shape: ', y.shape)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Data \n",
    "\n",
    "We see above that the data features are 4-D.\n",
    "Generate two visualizations of the data using Red, Blue, Green for the colors of\n",
    "`setosa`, `versicolor`, `virginica`, respectively.\n",
    "\n",
    "### Task 2: First, visualize along dimensions 0,1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P02)\n",
    "# ----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Second, visualize along dimensions 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P03)\n",
    "# ----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a NN model\n",
    "\n",
    "### Task 4: Define the neural architecture with PyTorch with the following config\n",
    "\n",
    "1. A hidden layer with 4 neurons\n",
    "2. Use sigmoid activation fuction for the hidden layer\n",
    "3. Convert the output layer values to probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        D_in: number of input\n",
    "        H: Number of neurons in the hidden layer\n",
    "        D_out: number of output\n",
    "        \"\"\"\n",
    "        super(MyModel, self).__init__()\n",
    "        # define layers here\n",
    "        <placeholder>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_pred = <placeholder> \n",
    "        y_pred = <placeholder>  \n",
    "        return y_pred\n",
    "\n",
    "# Create a model instance\n",
    "\n",
    "D_in = <placeholder>\n",
    "H = <placeholder>\n",
    "D_out = <placeholder>\n",
    "\n",
    "model = MyModel(<placeholder>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Define the loss funciton and optimizer \n",
    "\n",
    "Deine the loss function as `CrossEntropyLoss` and compile the model with the `rmsprop` optimizer. Pick a suitable learning rate (`lr`). \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P05)\n",
    "# ----------------------------------\n",
    "\n",
    "loss = <placeholder>\n",
    "optimizer = <placeholder>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the Data into Train and Test splits\n",
    "\n",
    "To make this this more fun, we are going to use a 70%/30% split on the training and testing data.\n",
    "\n",
    "### Task 6: Prepare the data for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P06)\n",
    "# ----------------------------------\n",
    "\n",
    "# scale the data either with StandardScaler or Normalizer\n",
    "scaler = <placeholder>\n",
    "X_scaled = <placeholder>\n",
    "\n",
    "\n",
    "\n",
    "# train/test split \n",
    "X_train, X_test, y_train, y_test = <placeholder>\n",
    "\n",
    "\n",
    "# convert train/test to tensors\n",
    "X_train_tensor = torch.tensor(<placeholder>)\n",
    "X_test_tensor = torch.tensor(<placeholder>)\n",
    "y_train_tensor = torch.tensor(<placeholder>).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(<placeholder>).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "\n",
    "BATCH_SIZE = 1  # it is possible to feed more than one istances to the model. \n",
    "# These set of instances is called batch. For simplicity, let's keep one instance per batch\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=<placeholder>, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=<placeholder>, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Train the model on the train data\n",
    "\n",
    "Choose an appropriate number of epochs and batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P07)\n",
    "# ----------------------------------\n",
    "\n",
    "N_EPOCHS = 100  # In each epoch, the model iterate over all the instances \n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        y_pred = <placeholder>      # Forward pass: get the network output for this instance\n",
    "        \n",
    "        l = loss(y_pred, y.view(-1))    # estimate error for this instance\n",
    "        # here y is a 2D variable (1,1); y.view(-1) makes it a vector\n",
    "        \n",
    "        epoch_loss += l.item() # Aggregate error\n",
    "        \n",
    "        optimizer.zero_grad()  # As backward method accumulates gradient, we need to set it to 0\n",
    "        <placeholder>           # Backward pass: Estimate gradient \n",
    "        optimizer.step()\n",
    "        \n",
    "        correct = (torch.argmax(y_pred, dim=1) == y).type(torch.FloatTensor)\n",
    "        epoch_acc += correct.item()\n",
    "\n",
    "    if (epoch%5)==0:\n",
    "        print(f'Epoch {epoch+0:03}: | Total Loss: {epoch_loss:.5f} | \\\n",
    "Avg Loss: {epoch_loss/len(train_loader):.5f} | Training Acc: {epoch_acc/len(train_loader):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Task 8: Evaluate your trained model on the on the test data\n",
    "\n",
    "Print the loss and accuracy obtained using model.evaluate(...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P08)\n",
    "# ----------------------------------\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    <placeholder> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Interpret the classifier output\n",
    "\n",
    "Run the cell below, then provide your interpretation of the output in the cell below that.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add interpretation below this comment  (Question #P09)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Print the predicted class label, then generate a confusion matrix and flassification report\n",
    " * Review the documentation: https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix code below this comment  (Question #P10)\n",
    "# ----------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## This notebook should include things that you are adding to your toolchest in terms of using Scikit-Learn and PyTorch\n",
    "\n",
    "---\n",
    "\n",
    "# Save your notebook, then `File > Close and Halt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
