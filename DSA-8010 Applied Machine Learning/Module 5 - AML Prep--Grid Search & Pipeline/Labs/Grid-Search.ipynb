{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Parameter Tuning\n",
    "\n",
    "In the first three modules, we learned several models and fitted them using some parameters that are user-defined (aka Hyperparameters). Hyperparameters are parameters of the model that are not learned. \n",
    "The default values or manual setting of values for hyperparameter are often a good start, but they may not produce the optimal model. Instead of hand picking values, it is possible to automate this process using grid search and random search. In this lab we breifly intrduce grid search and we will continue our discussion on grid search and random search in Module 5.  \n",
    "\n",
    "\n",
    "Grid search is a common method to select the hyperparameter values that produce the best model. Grid search takes a set of possible values for each hyperparameter that should be tuned, and evaluates a model trained on each  possible combination of the hyperparameter values. It is an exhaustive search that trains and evaluates a model for each possible combination. A disadvantage of grid search is that it is computationally costly for even small sets of hyperparameter values. Fortunately, it is an embarrassingly parallel problem; many models can easily be trained and evaluated concurrently since no synchronization is required between the processes.\n",
    "\n",
    "In this lab we look at grid search with a simple example: we vary some parameters of the DecisionTree method, and learn the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load irish dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "irish = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veiw data\n",
    "print(irish.feature_names)\n",
    "print(irish.data[:5,])\n",
    "print(irish.target_names)\n",
    "print(irish.target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure hyperparameter space\n",
    "\n",
    "To tune the model, we need to provide a set of hyperparameters and a range of values for each of them.  \n",
    "Here is the parameter list we try out with `DecisionTreeClassifier`. To learn more about this hyperparameters, check here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'min_samples_leaf': [2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above configuration, grid search learns (2 * 3 * 2 = 12) candidate models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = irish.data\n",
    "y = irish.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute grid search\n",
    "\n",
    "For performing grid search, we use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with a model and a configuration of the hyperparameters. This method seraches all the possible combinations and choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_analyzer = GridSearchCV(DecisionTreeClassifier(), \n",
    "                             params_list, refit = True, verbose = 3, n_jobs=-1)\n",
    "\n",
    "grid_analyzer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyperparams identified by grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_analyzer.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with the best model\n",
    "\n",
    "We don't need to retrain the model with the best combination of hyperparameters as grid search object can do this job for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = grid_analyzer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the tree of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(35,20))\n",
    "tree = DecisionTreeClassifier(criterion=grid_analyzer.best_params_['criterion'],\n",
    "                             min_samples_split=grid_analyzer.best_params_['min_samples_split'],\n",
    "                             min_samples_leaf=grid_analyzer.best_params_['min_samples_leaf'])\n",
    "tree.fit(X_train, y_train)\n",
    "a = plot_tree(tree, \n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
