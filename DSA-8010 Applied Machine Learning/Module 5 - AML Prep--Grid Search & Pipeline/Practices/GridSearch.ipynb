{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Practice\n",
    "\n",
    "Grid search is a way of finding better hypermeters, those that define the configuration of the model and not altered by learning of the model.\n",
    "It is also known as Exhaustive Grid Search, because it takes many parameter options and creates a search space with cartesian product and then exhaust and evaluate all of these possibilities.\n",
    "In essence, it is a brute force algorithm.\n",
    "Let's get familiarize with its usage through practice.\n",
    "\n",
    "First, we prepare some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "DATASET = '/dsa/data/all_datasets/titanic_ML/titanic.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.survived\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Grid\n",
    "\n",
    "As a model selection approach, the grid search allows you to investigate the optimal choice of model parameters by specifying the variations for each parameter.\n",
    "\n",
    "For example, the SVC model has an error penalty parameter `C` in the model,\n",
    "and we can specify the parameter grid as a dictionary, with the name of the parameter in question, then define the variations of the parameter in a list:\n",
    "\n",
    "```python\n",
    "param_grid = {'C': [1e3, 1e4] }\n",
    "```\n",
    "\n",
    "The dictionary allows us to supply the variations for different parameters:\n",
    "\n",
    "```python\n",
    "param_grid = {'C': [1e3, 1e4],\n",
    "              'gamma': [1e-4, 1e-3], }\n",
    "```\n",
    "\n",
    "Conceptually, the parameter grid dictionary represents a cartesian product of the parameter variations, which contains all the configurations of the models that will be evaluated.  \n",
    "In other words, the above `param_grid` helps to set up the following 4 models to evaluate:\n",
    "\n",
    "```python\n",
    "SVC(C=1e3, gamma=1e-4, ...)\n",
    "SVC(C=1e3, gamma=1e-3, ...)\n",
    "SVC(C=1e4, gamma=1e-4, ...)\n",
    "SVC(C=1e4, gamma=1e-3, ...)\n",
    "```\n",
    "\n",
    "But sometimes this kind of cartesian product will generate too many models, more than desired.\n",
    "We can also provide multiply dictionaries as alternative options.\n",
    "\n",
    "Consider the difference between\n",
    "```python\n",
    "param_grid = [{'C': [1e3, 3e3],\n",
    "              'gamma': [1e-4, 1e-3], },\n",
    "             {'C': [5e2, 1e3],\n",
    "              'gamma': [5e-5, 1e-4], }]\n",
    "=> 2*2+2*2 = 8 models\n",
    "\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "param_grid = [{'C': [1e3, 3e3, 5e2],\n",
    "              'gamma': [1e-4, 1e-3, 5e-5], }]\n",
    "=> 3*3 = 9 models\n",
    "```\n",
    "\n",
    "## Cross Validation\n",
    "\n",
    "Not only does the Grid Search help you set up various configurations of models, it also sets up cross validation to provide more objective evaluation metrics of these models. `cv` parameter is used to specify number of cross validation folds used for evaluation.\n",
    "\n",
    "## Practice\n",
    "\n",
    "With the parameter grid and cross validation, the grid search results in a lot of computation.\n",
    "However, we can leverage multiple processors available to accelerate the task, with `n_jobs` parameter, although be aware that in your Jupyter server learning environment, there may be resource limits to ensure fairness, i.e. you may not be able to use as many CPU cores as you can see, so we use a relatively low number in that parameter.\n",
    "\n",
    "Now let's practice GridSearchCV usage, create a GridSearchCV, **named `clf`**:\n",
    "\n",
    "1. Create at least 8 models with variations in `C`, `gamma` or your choice.\n",
    "2. Use 5 fold cross validation.\n",
    "3. Use 2 parallel jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code for the above task here:   (Question #P001)\n",
    "# ----------------------------------------\n",
    "param_grid = [{'C': [1e3, 2e3],\n",
    "              'gamma': [1e-4, 1e-3], },\n",
    "             {'C': [5e2, 1e3],\n",
    "              'gamma': [5e-5, 3e-4], }]\n",
    "clf = GridSearchCV(SVC(kernel = 'rbf', class_weight = 'balanced'),\n",
    "                   param_grid, cv = 5, n_jobs = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to loaded data `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced'), n_jobs=2,\n",
       "             param_grid=[{'C': [1000.0, 2000.0], 'gamma': [0.0001, 0.001]},\n",
       "                         {'C': [500.0, 1000.0], 'gamma': [5e-05, 0.0003]}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code for the above task here:   (Question #P002)\n",
    "# ----------------------------------------\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2000.0, class_weight='balanced', gamma=0.0001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearchCV creates an abstract classifier, once trained with cross validation, the returned object itself can be used as a classifier that represent the optimal classifier within the given hyperparameter space.\n",
    "For example, from the example above, `clf` will have many familiar methods like `.predict()`, `.score()`.\n",
    "\n",
    "In addition, `clf.best_estimator_` gives you access to the best model chosen; `clf.best_score_` stores the accuracy score for the best model as well; `clf.cv_results_` provides details on cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08175302, 0.16797867, 0.13424835, 0.32009592, 0.05432243,\n",
       "        0.07824359, 0.07279572, 0.14306188]),\n",
       " 'std_fit_time': array([0.00942083, 0.04143124, 0.01801916, 0.05124984, 0.01172544,\n",
       "        0.01925602, 0.011789  , 0.05972734]),\n",
       " 'mean_score_time': array([0.00596814, 0.0059    , 0.00592299, 0.00588446, 0.00648656,\n",
       "        0.00595622, 0.00626373, 0.00593266]),\n",
       " 'std_score_time': array([1.35640803e-04, 2.33837879e-04, 7.43120382e-05, 1.45119606e-04,\n",
       "        1.40339308e-04, 7.63602862e-05, 1.65065776e-04, 1.21409764e-04]),\n",
       " 'param_C': masked_array(data=[1000.0, 1000.0, 2000.0, 2000.0, 500.0, 500.0, 1000.0,\n",
       "                    1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0001, 0.001, 0.0001, 0.001, 5e-05, 0.0003, 5e-05,\n",
       "                    0.0003],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1000.0, 'gamma': 0.0001},\n",
       "  {'C': 1000.0, 'gamma': 0.001},\n",
       "  {'C': 2000.0, 'gamma': 0.0001},\n",
       "  {'C': 2000.0, 'gamma': 0.001},\n",
       "  {'C': 500.0, 'gamma': 5e-05},\n",
       "  {'C': 500.0, 'gamma': 0.0003},\n",
       "  {'C': 1000.0, 'gamma': 5e-05},\n",
       "  {'C': 1000.0, 'gamma': 0.0003}],\n",
       " 'split0_test_score': array([0.79775281, 0.74719101, 0.80898876, 0.74719101, 0.79213483,\n",
       "        0.78089888, 0.79775281, 0.75842697]),\n",
       " 'split1_test_score': array([0.80898876, 0.81460674, 0.82022472, 0.82022472, 0.81460674,\n",
       "        0.79775281, 0.81460674, 0.79775281]),\n",
       " 'split2_test_score': array([0.76966292, 0.78089888, 0.78651685, 0.7752809 , 0.76966292,\n",
       "        0.7752809 , 0.76966292, 0.7752809 ]),\n",
       " 'split3_test_score': array([0.70224719, 0.70786517, 0.74719101, 0.70786517, 0.71348315,\n",
       "        0.74719101, 0.71910112, 0.75280899]),\n",
       " 'split4_test_score': array([0.74157303, 0.73033708, 0.73033708, 0.71910112, 0.73033708,\n",
       "        0.73595506, 0.73033708, 0.74157303]),\n",
       " 'mean_test_score': array([0.76404494, 0.75617978, 0.77865169, 0.75393258, 0.76404494,\n",
       "        0.76741573, 0.76629213, 0.76516854]),\n",
       " 'std_test_score': array([0.03875997, 0.03770328, 0.03474073, 0.04057409, 0.0376027 ,\n",
       "        0.02263982, 0.03702754, 0.01959056]),\n",
       " 'rank_test_score': array([5, 7, 1, 8, 6, 2, 3, 4], dtype=int32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.081753      0.009421         0.005968        0.000136  1000.0   \n",
      "1       0.167979      0.041431         0.005900        0.000234  1000.0   \n",
      "2       0.134248      0.018019         0.005923        0.000074  2000.0   \n",
      "3       0.320096      0.051250         0.005884        0.000145  2000.0   \n",
      "4       0.054322      0.011725         0.006487        0.000140   500.0   \n",
      "5       0.078244      0.019256         0.005956        0.000076   500.0   \n",
      "6       0.072796      0.011789         0.006264        0.000165  1000.0   \n",
      "7       0.143062      0.059727         0.005933        0.000121  1000.0   \n",
      "\n",
      "  param_gamma                          params  split0_test_score  \\\n",
      "0      0.0001  {'C': 1000.0, 'gamma': 0.0001}           0.797753   \n",
      "1       0.001   {'C': 1000.0, 'gamma': 0.001}           0.747191   \n",
      "2      0.0001  {'C': 2000.0, 'gamma': 0.0001}           0.808989   \n",
      "3       0.001   {'C': 2000.0, 'gamma': 0.001}           0.747191   \n",
      "4     0.00005    {'C': 500.0, 'gamma': 5e-05}           0.792135   \n",
      "5      0.0003   {'C': 500.0, 'gamma': 0.0003}           0.780899   \n",
      "6     0.00005   {'C': 1000.0, 'gamma': 5e-05}           0.797753   \n",
      "7      0.0003  {'C': 1000.0, 'gamma': 0.0003}           0.758427   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0           0.808989           0.769663           0.702247           0.741573   \n",
      "1           0.814607           0.780899           0.707865           0.730337   \n",
      "2           0.820225           0.786517           0.747191           0.730337   \n",
      "3           0.820225           0.775281           0.707865           0.719101   \n",
      "4           0.814607           0.769663           0.713483           0.730337   \n",
      "5           0.797753           0.775281           0.747191           0.735955   \n",
      "6           0.814607           0.769663           0.719101           0.730337   \n",
      "7           0.797753           0.775281           0.752809           0.741573   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.764045        0.038760                5  \n",
      "1         0.756180        0.037703                7  \n",
      "2         0.778652        0.034741                1  \n",
      "3         0.753933        0.040574                8  \n",
      "4         0.764045        0.037603                6  \n",
      "5         0.767416        0.022640                2  \n",
      "6         0.766292        0.037028                3  \n",
      "7         0.765169        0.019591                4  \n"
     ]
    }
   ],
   "source": [
    "clf_df = pd.DataFrame(clf.cv_results_)\n",
    "print(clf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from `clf.cv_results_`, can you find where did the value of `clf.best_score_` come from?\n",
    "\n",
    "Copy-paste the key/value pair from `clf.cv_results_` that shows the source of `clf.best_score_` below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Enter your answer below   (Question #P003)\n",
    "# ----------------------------------------\n",
    "'mean_test_score': array([0.76404494, 0.75617978, 0.77865169, 0.75393258, 0.76404494,\n",
    "        0.76741573, 0.76629213, 0.76516854])\n",
    "'rank_test_score': array([5, 7, 1, 8, 6, 2, 3, 4], dtype=int32)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which was the fastest model to train? What were the parameters to the fastest model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Enter your answer below   (Question #P004)\n",
    "# ----------------------------------------\n",
    "The fifth model was the fastest with parameters of C:500 and gamma:5e-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a prediction on the first 5 data samples from `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your answer below   (Question #P005)\n",
    "# ----------------------------------------\n",
    "clf.predict(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
