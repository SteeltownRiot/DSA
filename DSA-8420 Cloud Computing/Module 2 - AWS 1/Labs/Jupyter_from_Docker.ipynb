{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Jupyter from a Docker in EC2 instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Docker Reference: ](http://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html)\n",
    "\n",
    "\n",
    "\n",
    "From the Docker website, Docker is the world’s leading software container platform. Developers use Docker to eliminate \"works on my machine\" problems when collaborating on code with co-workers. Operators use Docker to run and manage apps side-by-side in isolated containers to get better compute density. Enterprises use Docker to build agile software delivery pipelines to ship new features faster, more securely and with confidence for both Linux, Windows Server, and Linux-on-mainframe apps.\n",
    "\n",
    "#### What is a Container?\n",
    "\n",
    "Containers are a way to package software in a format that can run isolated on a shared operating system. Unlike VMs, containers do not bundle a full operating system - only libraries and settings required to make the software work are needed. This makes for efficient, lightweight, self-contained systems and guarantees that software will always run the same, regardless of where it’s deployed.\n",
    "\n",
    "\n",
    "#### Docker For Developers\n",
    "\n",
    "Docker automates the repetitive tasks of setting up and configuring development environments so that developers can focus on what matters: building great software.\n",
    "\n",
    "Here in this notebook, we will set up a docker container inside an EC2 instance. It demonstrates launching a docker container which runs Jupyter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the steps\n",
    "\n",
    "* Launch an EC2 instance with the Amazon Linux AMI.\n",
    "* SSH into the instance.\n",
    "* Update the packages and package cache on the instance.\n",
    "* Install additional required packages.\n",
    "* Install Docker image on the instance which has Jupyter already installed in it.\n",
    "* Open Jupyter in the docker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### SET THE FOLLOWING PARAMETERS ###################################################\n",
    "#Set the AWS Region\n",
    "region = 'us-east-1'\n",
    "\n",
    "\n",
    "ami_image = 'ami-8c1be5f6'\n",
    "\n",
    "#Set the AWS Access ID (Given to you buy the DSA staff: \"Access key ID\")\n",
    "access_id = 'Put your access key id here'\n",
    "\n",
    "#Set the AWS Access Key (Given to you buy the DSA staff: \"Secret access key\")\n",
    "access_key = 'Put your secret access key here'\n",
    "\n",
    "#Security group name: Add your pawprint here\n",
    "Sec_group_name= \"Docker_your_pawprint_Sec_group\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will be using Boto3 python package to use AWS services. \n",
    "Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, \n",
    "which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2. \n",
    "Boto3 has two distinct levels of APIs. Client (or \"low-level\") APIs provide one-to-one mappings to the underlying HTTP API operations. \n",
    "Resource APIs hide explicit network calls but instead provide resource objects and collections to access attributes and perform actions.\n",
    "\n",
    "\n",
    "There is always a confusion between client and resource as to when to use what. \n",
    "You don't see the subtle difference when using a client or resource object. \n",
    "The resource API is still under development. So there would be more to offer in future through resource API.\n",
    "Below readings might help you understand the difference between client and resource.\n",
    "\n",
    "\n",
    "\n",
    "[Client](http://boto3.readthedocs.io/en/latest/guide/clients.html)\n",
    "\n",
    "[Resource](http://boto3.readthedocs.io/en/latest/guide/resources.html)\n",
    "\n",
    "### Create a EC2 client object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AWS' Python Based DEVOPS tools\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#Import System Tools\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import pandas\n",
    "import time\n",
    "import getpass\n",
    "from subprocess import call\n",
    "\n",
    "#Set the username from system\n",
    "system_user_name=getpass.getuser()\n",
    "\n",
    "# client interface.\n",
    "# Estabilish Credentials/Session\n",
    "ec2 = boto3.client(\n",
    "    'ec2', \n",
    "    region_name=region,\n",
    "    aws_access_key_id=access_id,\n",
    "    aws_secret_access_key=access_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a security group in module 1 from the web console. We will create a similar security group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = ec2.create_security_group(\n",
    "    Description='security grp for docker',\n",
    "    GroupName=Sec_group_name   # We have set this variable above\n",
    ")\n",
    "Sec_group=sg[\"GroupId\"]     # Sec_group should have the new security group ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like module 1 we have to SSH into the EC2 instance. So customize the security group to allow MU's TCP traffic and SSH requests. Configure the inbound rules to allow traffic as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify Security Configuration to allow MU's IP addresses\n",
    "\n",
    "#Describe Cluster\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL TCP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},\n",
    "        ],)\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL TCP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "#              'IpRanges': [{'CidrIp': Sec_group}]},\n",
    "            }],\n",
    "#         SourceSecurityGroup=Sec_group_name\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "\n",
    "try:\n",
    "    sec_rule=\"Custom ICMP Rule - IPv4\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': -1,\n",
    "             'IpRanges': [{'CidrIp': '173.31.192.195/32'}]},\n",
    "        ])\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "try:\n",
    "    sec_rule=\"ALL UDP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'udp',\n",
    "             'FromPort': 0,\n",
    "             'ToPort': 65535,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n",
    "\n",
    "    \n",
    "try:\n",
    "    sec_rule=\"ALL ICMP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': -1,\n",
    "             'ToPort': -1,\n",
    "             'UserIdGroupPairs': [{ 'GroupId': Sec_group }]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    sec_rule=\"ALL ICMP\"\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'icmp',\n",
    "             'FromPort': -1,\n",
    "             'ToPort': -1,\n",
    "             'IpRanges': [{'CidrIp': '0.0.0.0/16'}]\n",
    "            }],\n",
    "    )\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a keypair for the EC2 instance. We first generate a name to create a key with that name and also store the key in a file. ec2.create_key_pair() will create a keypair. System command echo is used to write the contents of keypair generated to a file created with same name as keypair. \n",
    "\n",
    "You have to modify the file permissions to provide readonly access. If the file is open, system will throw an error. Do chmod(file, 0o400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import os\n",
    "\n",
    "ec2_pem_file=time.strftime(\"EC2-%d%m%Y%H%M%S-\"+system_user_name)\n",
    "ec2_key=ec2.create_key_pair(KeyName=ec2_pem_file)\n",
    "\n",
    "#Don't do this unless you have a good reason\n",
    "#print(emr_key['KeyMaterial'])\n",
    "\n",
    "os.system(\"echo \\\"\"+ec2_key['KeyMaterial']+\"\\\" > \"+ec2_pem_file+\".pem\")\n",
    "os.chmod(ec2_pem_file+\".pem\",0o400)\n",
    "\n",
    "print(\"KeyName         : \"+ec2_key['KeyName']+\"\\nKey Fingerprint : \"+ec2_key['KeyFingerprint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch an instance using the keypair and the security group created above. We only need one instance to run\n",
    "\n",
    "**MaxCount:** The maximum number of instances to launch. If you specify more instances than Amazon EC2 can launch in the target Availability Zone, Amazon EC2 launches the largest possible number of instances above MinCount .\n",
    "\n",
    "\n",
    "**MinCount:** The minimum number of instances to launch. If you specify a minimum that is more instances than Amazon EC2 can launch in the target Availability Zone, Amazon EC2 launches no instances.\n",
    "\n",
    "Constraints: Between 1 and the maximum number you're allowed for the specified instance type.\n",
    "\n",
    "In Tags, we are giving a name tag to the isntance to identify it by the name `Docker_Jupyter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Instance\n",
    "instances = ec2.run_instances(\n",
    "    ImageId=ami_image,\n",
    "    MinCount=1,\n",
    "    MaxCount=1,\n",
    "    KeyName=ec2_pem_file,\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'instance',\n",
    "            'Tags': [\n",
    "                        {   'Key': 'Name',\n",
    "                            'Value': 'Docker_Jupyter'\n",
    "                        }\n",
    "                    ]\n",
    "        }\n",
    "    ],\n",
    "    InstanceType=\"t2.micro\",\n",
    "    SecurityGroupIds=[\n",
    "        Sec_group\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the instance id of new instance. The output in the variable \"instances\" has details of instances created in above cell. Its a dictionary. \n",
    "\n",
    "- In the below cell, `\"Instances\"` in `instances[\"Instances\"]` is the key. It will give corresponding value associated with the key. So we have the instance details now.\n",
    "- We know we created only 1 instance. We mentioned that with Mincount and MaxCount set to 1. So access the details of that instance using the index 0. \n",
    "- Finally for the one instance created, get the InstanceId into new_instance_id variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instance_id = instances[\"Instances\"][0][\"InstanceId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the instanceId captured above, use `describe_instances()` method to get instance details. \n",
    "`describe_instances()` has public DNS address of the instance. \n",
    "We are filtering the results to the latest instance we created in this notebook by using a filter as shown below. \n",
    "If there are multiple instances present in the specified region, we dont want details of all the instances. \n",
    "\n",
    "```\n",
    "InstanceIds=[\n",
    "        new_instance_id,\n",
    "    ]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_det = ec2.describe_instances(\n",
    "    InstanceIds=[\n",
    "        new_instance_id,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the public DNS of new instance. The output in the variable \"inst_det\" has details of the instance, like public DNS, public IP address, private IP address etc. Its a dictionary again. \n",
    "\n",
    "- In the below cell, `inst_det[\"Reservations\"]` gives corresponding value associated with the key `Reservations`. \n",
    "- Again access the only keypair in the list with an index 0. \n",
    "- `\"Instances\"` in `inst_det[\"Reservations\"][0][\"Instances\"][0]` is the key and gived corresponding details associated with the key. So we have the instance details now.\n",
    "- Finally, capture the PublicDnsName name of instance in instance_pub_dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_pub_dns=inst_det[\"Reservations\"][0][\"Instances\"][0][\"PublicDnsName\"]\n",
    "instance_pub_dns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function accepts ec2 client and the instance id. \n",
    "It uses the same code as above cell except here it is trying to get the state of the instance id passed as input. \n",
    "If the instance is in running or terminated state it will break out of the while loop and prints that the instance is running or terminated.\n",
    "\n",
    "If the instance is in any other state like waiting to be set up or terminating, it keeps polling in regular intervals as per the delay. \n",
    "`time.sleep()` will sleepm for specified time and checks the status of instance in the while loop. \n",
    "\n",
    "```\n",
    "\n",
    "delay *= random.uniform(1.1, 2.0)\n",
    "        time.sleep(delay) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_until_completed(client, ins_id):\n",
    "    delay = 2\n",
    "    while True:\n",
    "        instance = client.describe_instances(InstanceIds=[ins_id,])\n",
    "        status = instance[\"Reservations\"][0][\"Instances\"][0][\"State\"][\"Name\"]\n",
    "#         message = cluster.get('Message', '')\n",
    "        now = str(datetime.datetime.now().time())\n",
    "    \n",
    "        print(\"instance %s is %s at %s\" % (ins_id, status, now))\n",
    "        if status in ['running','terminated']:\n",
    "            break\n",
    "\n",
    "        # exponential backoff with jitter\n",
    "        delay *= random.uniform(1.1, 2.0)\n",
    "        time.sleep(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the poll_until_completed() with ec2 client and instance id as parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "poll_until_completed(ec2, new_instance_id)  # Can't use it until it's COMPLETED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a file to S3. You will access this file in the Jupyter notebook you will run inside docker.\n",
    "\n",
    "\n",
    "\"bgg_db_2017_03.csv\" is the file available in your local directory. Upload this file to S3, so you can access the same file in Jupyter running in docker container on EC2 instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Connection\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3', \n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name= system_user_name+time.strftime(\".%d%m%Y%H%M%S\")+'.dsabucket'\n",
    "s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={\n",
    "    'LocationConstraint': 'us-west-2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading files S3 Bucket. \n",
    "s3.upload_file('bgg_db_2017_03.csv',bucket_name,'board_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSH into EC2 instance\n",
    "\n",
    "SSH into the EC2 instance you just created through terminal. \n",
    "\n",
    "* Open up a terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the keypair file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keypair file name:\",ec2_pem_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open up a terminal.\n",
    "\n",
    "\n",
    "* Step 1: change into the course folder\n",
    "\n",
    "\n",
    "* Step 2: Update the permissions on keypair file\n",
    "\n",
    "    `Run below cell and copy the output. paste it in the terminal. This will make the keypair file readonly.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"chmod 400 \"+os.getcwd()+\"/\"+ec2_pem_file+\".pem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below and copy the output. \n",
    "\n",
    "* Paste the output in terminal and hit enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ssh -i \"+os.getcwd()+\"/\"+ec2_pem_file+\".pem ec2-user@\"+instance_pub_dns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/SSH_command.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the below list of commands "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the next 5 screenshots for updating the packages and installing new software. \n",
    "\n",
    "* sudo su\n",
    "\n",
    "* yum update –y\n",
    "\n",
    "\n",
    "<img src=\"../images/update_packages.png\">\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "* yum install -y docker\n",
    "\n",
    "* service docker start\n",
    "\n",
    "\n",
    "<img src=\"../images/install_docker.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* usermod -a -G docker ec2-user\n",
    "\n",
    "* yum install python38\n",
    "\n",
    "* yum -y update\n",
    "\n",
    "\n",
    "<img src=\"../images/update_packages_again.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* wget https://bootstrap.pypa.io/get-pip.py\n",
    "\n",
    "* python3 get-pip.py\n",
    "\n",
    "* /usr/local/bin/pip install boto3\n",
    "\n",
    "\n",
    "<img src=\"../images/install_pip_boto3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start docker service and download docker image that has Jupyter installed\n",
    "\n",
    "* sudo service docker start\n",
    "\n",
    "* docker run -it --rm -p 8888:8888 jupyter/scipy-notebook\n",
    "\n",
    "\n",
    "<img src=\"../images/run_docker.PNG\">\n",
    "\n",
    "<br>\n",
    "Docker will give a URL with a token. This URL will allow to open up Jupyter on EC2 instance. Copy(**select the URL with mouse, right click and then copy**) the URL docker gave as output and paste it in browser window. While pasting the URL, delete localhost from URL and replace it with the public DNS address of instance. \n",
    "\n",
    "For example (not a useable link),\n",
    "\n",
    "http://ec2-54-201-248-103.us-west-2.compute.amazonaws.com:8888/?token=d8e2791504cb6623b3ab0d97f69aa74c583457f59f379c9a\n",
    "\n",
    "-----\n",
    "<br>\n",
    "Paste the URL in your local browser\n",
    "\n",
    "\n",
    "<img src=\"../images/jupyter_running.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Access_S3.ipynb notebook\n",
    "\n",
    "\n",
    "Now that you have Jupyter running in the docker container, lets run a python notebook there. There is a python notebook \"Access_S3.ipynb\" in the current directory \"CloudComputingDataAnalytics/module2/labs/\". Download the file to your local machine and upload the same into Jupyter running in Docker. Select Access_S3.ipynb file and click on download.\n",
    "\n",
    "\n",
    "Use the upload button in Jupyter present in your current working directory to the docker. \n",
    "\n",
    "Below code cell will upload the file using scp command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the file Access_S3.ipynb\n",
    "\n",
    "\n",
    "Go to Jupyter running on Docker, use the upload button to upload Access_S3.ipynb. \n",
    "Access_S3 notebook in the local machine is copied to Jupyter on Docker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once Jupyter is up and running, open up a terminal and run below command to install boto3. \n",
    "    \n",
    "    pip install boto3\n",
    "    \n",
    "Close the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run all the cells in the notebook. The boardgames  dataset should be downloaded in docker jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete SSH Keypair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SSH Keypair\n",
    "\n",
    "try:\n",
    "    os.remove(ec2_pem_file+'.pem')\n",
    "    print('Local Key Deleted')\n",
    "except:\n",
    "    print('Local Key Not Found')\n",
    "    \n",
    "response = ec2.delete_key_pair(KeyName=ec2_pem_file)\n",
    "print('\\nAWS Metadata: ')\n",
    "print('http Status Code : '+str(response['ResponseMetadata']['HTTPStatusCode']))\n",
    "print('Request ID       : '+response['ResponseMetadata']['RequestId'])\n",
    "print('Retries          : '+str(response['ResponseMetadata']['RetryAttempts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate the EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec22 = boto3.resource('ec2',region_name=region,\n",
    "                   aws_access_key_id = access_id, \n",
    "                   aws_secret_access_key = access_key)\n",
    "\n",
    "ec22.Instance(new_instance_id).terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the security group\n",
    "\n",
    "Note: Make sure the instance is terminated before deleting the security group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "poll_until_completed(ec2, new_instance_id)  # Can't use it until it's COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_delete_response = ec2.delete_security_group(\n",
    "    GroupId=Sec_group,\n",
    ")\n",
    "SG_delete_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"background:yellow\">Below cells are just for reference</span></h1>\n",
    "\n",
    "\n",
    "### Paramiko Python Package\n",
    "\n",
    "There is a python library called paramiko which will let you ssh into a remote machine and execute commands in terminal. For now, lets keep it simple. Commands in below cell actually use paramiko library commands to establish the connection by doing SSH into the EC2 instance. The commnads install docker software, start the container and add ec2-user to the docker group so that it can be accessed. At the end, python 3.4 is installed and boto3 package is installed. \n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "When you SSH into an EC2 instance, remember the machine always does SSH checking and asks for confirmation if we want to trust the machine we are getting into. We need to be careful to get through SSH checking and actually get into the instance. \n",
    "\n",
    "For that matter if you often launch new EC2 instances, start and stop EC2 instances, without using Elastic IPs (permanently attached to servers) then we would be dealing with new/changing IPs/hostnames of instances all the time. In that case if you want to permanently stop SSH checking and storing server fingerprints for EC2 public hostnames, add below lines to the ~/.ssh/config file. \n",
    "\n",
    "----\n",
    "\n",
    "$#$ AWS EC2 public hostnames (changing IPs)\n",
    "\n",
    "    Host *.compute.amazonaws.com\n",
    "\n",
    "    StrictHostKeyChecking no\n",
    "\n",
    "    UserKnownHostsFile /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't run this cell. \n",
    "\n",
    "# import boto3\n",
    "# import botocore\n",
    "# import paramiko\n",
    "\n",
    "# client = paramiko.SSHClient()\n",
    "# client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "# # Connect/ssh to an instance\n",
    "# try:\n",
    "#     # hostname is public DNS address of EC2 instance, key_filename is the private key to connect to instance.\n",
    "#     print(\"Trying to connect\")\n",
    "    \n",
    "#     client.connect(hostname=instance_pub_dns, username='ec2-user', key_filename=\"EC2KeyPair1.pem\")\n",
    "#     print(\"connected to instance\")\n",
    "    \n",
    "#     print(\"\"\"Update all the existing packages, \n",
    "#           Install the most recent Docker Community Edition package, \n",
    "#           Start the Docker service.\n",
    "#           Add the ec2-user to the docker group so you can execute Docker commands without using sudo. \n",
    "#           Log out with exit() command. \"\"\" )\n",
    "    \n",
    "#     stdin, stdout, stderr = client.exec_command(\"sudo su; yum update –y; yum install -y docker; service docker start;\\\n",
    "#     usermod -a -G docker ec2-user; yum install python34; yum -y update; yum install boto3; exit\")\n",
    "    \n",
    "#     print(\"stdout: \",stderr)\n",
    "    \n",
    "#     print(\" log back in again to pick up the new docker group permissions.\")\n",
    "#     client.connect(hostname=instance_pub_dns, username='ec2-user', key_filename=\"EC2KeyPair1.pem\")\n",
    "#     print(\"connected to instance back\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the below cell is intimidating. It actually invokes a terminal session and starts the docker service. The command \"docker run -it --rm -p 8888:8888 jupyter/scipy-notebook\" is to tell docker to run the docker image jupyter/scipy-notebook. The image has Jupyter installed on it. \n",
    "\n",
    "Once the image is loaded, docker will spit a url like below with a token to access Jupyter. \n",
    "\n",
    "https://localhost:8888/?token=69df31aeebc2f1cd7bbdc8e78465bef30d11f02d462307a6\n",
    "\n",
    "\n",
    "Copy the url and append the EC2 instance public dns and paste the url (as shown below) in browser window to access Jupyter on EC2 instance. For example, \n",
    "\n",
    "\n",
    "https://ec2-54-202-203-168.us-west-2.compute.amazonaws.com:8888/?token=69df31aeebc2f1cd7bbdc8e78465bef30d11f02d462307a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ping from ec2-54-202-240-233.us-west-2.compute.amazonaws.com to 34.214.123.79\n",
    "\n",
    "# # two servers are in Oregon center\n",
    "\n",
    "# import paramiko\n",
    "# import sys\n",
    "# import time\n",
    "\n",
    "# class sampleParamiko:\n",
    "#     ssh = \"\"\n",
    "#     def __init__(self, host_DNS, uname, keyfile):\n",
    "#         try:\n",
    "#             self.ssh = paramiko.SSHClient()\n",
    "#             self.ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "#             self.ssh.connect(host_DNS, username=uname, key_filename=keyfile)\n",
    "#             #print \"In init function\"\n",
    "#         except (paramiko.BadHostKeyException, paramiko.AuthenticationException, paramiko.SSHException) as e:\n",
    "#             print(str(e))\n",
    "#             sys.exit(-1)\n",
    "\n",
    "#     def executeCmd(self,cmd):\n",
    "#         try:\n",
    "#             channel = self.ssh.invoke_shell()\n",
    "#             timeout = 60 # timeout is in seconds\n",
    "#             channel.settimeout(timeout)\n",
    "#             newline        = '\\r'\n",
    "#             line_buffer    = ''\n",
    "#             channel_buffer = ''\n",
    "#             channel.send(cmd + ' ; exit ' + newline)\n",
    "                \n",
    "#             while True:\n",
    "#                 channel_buffer = channel.recv(1).decode('UTF-8')\n",
    "#                 if len(channel_buffer) == 0:\n",
    "#                     break\n",
    "#                 channel_buffer  = channel_buffer.replace('\\r', '')\n",
    "#                 if channel_buffer != '\\n':\n",
    "#                     line_buffer += channel_buffer\n",
    "#                 else:\n",
    "#                     print(line_buffer)\n",
    "#                     line_buffer   = ''\n",
    "\n",
    "#         except paramiko.SSHException as e:\n",
    "#             print(str(e))\n",
    "#             sys.exit(-1)\n",
    "            \n",
    "# host_DNS = instance_pub_dns\n",
    "# username='ec2-user'\n",
    "# filename=\"EC2KeyPair1.pem\"\n",
    "\n",
    "# cmd = \"docker info\"\n",
    "# conn_obj = sampleParamiko(host_DNS, username, filename)\n",
    "# print(\"Verify that the ec2-user can run Docker commands without sudo.\")\n",
    "\n",
    "# try:\n",
    "#     print(\"Start the Docker service.\")\n",
    "#     stdin, stdout, stderr = client.exec_command(\"sudo service docker start\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "    \n",
    "# conn_obj.executeCmd(cmd)\n",
    "\n",
    "# cmd = \"docker run -it --rm -p 8888:8888 jupyter/scipy-notebook\"\n",
    "# conn_obj = sampleParamiko(host_DNS, username, filename)\n",
    "# conn_obj.executeCmd(cmd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cmd_list = [\"sudo su\",\"yum update –y\",\"yum install -y docker\",\"service docker start\",\"usermod -a -G docker ec2-user\",\"yum install python34\",\"yum -y update\",\"yum install boto3\",\"exit\"]\n",
    "\n",
    "# try:\n",
    "#     for cmd in cmd_list:\n",
    "#         print(cmd)\n",
    "#         conn_obj = sampleParamiko(host_DNS, username, filename)\n",
    "#         conn_obj.executeCmd(cmd)\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook and then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
