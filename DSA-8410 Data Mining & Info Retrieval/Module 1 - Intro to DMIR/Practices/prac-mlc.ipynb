{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will be using the CMU Movie Summary Corpus open dataset for this notebook. This dataset contains a list of movies and their genres. We can exploit movie summaries for predicting movie genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/dsa/data/DSA-8410/MovieSummaries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta = pd.read_csv(data_dir+\"movie.metadata.tsv\", sep = '\\t', header = None)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the proper column name for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "meta.columns = [\"movie_id\",\"freebase_movie_id\",\"movie_name\",\n",
    "                \"release_date\",\"revenue\",\"runtime\", \"languages\",\"countries\",\"genre\"]\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load movie plots\n",
    "The movie plot is in a different file. We need to load the plot separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "with open(data_dir + \"plot_summaries.txt\", 'r') as f:\n",
    "       reader = csv.reader(f, dialect='excel-tab') \n",
    "       for row in tqdm(reader):\n",
    "            plots.append(row)\n",
    "            \n",
    "movie_id = []\n",
    "plot = []\n",
    "\n",
    "# extract movie Ids and plot summaries\n",
    "for i in tqdm(plots):\n",
    "  movie_id.append(i[0])\n",
    "  plot.append(i[1])\n",
    "\n",
    "# create dataframe\n",
    "movies = pd.DataFrame({'movie_id': movie_id, 'plot': plot})\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Pre-processing\n",
    "Now add the meta information to the movies dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change datatype of 'movie_id'\n",
    "meta['movie_id'] = meta['movie_id'].astype(str)\n",
    "\n",
    "# merge meta with movie plots\n",
    "movies = pd.merge(movies, meta[['movie_id', 'movie_name', 'genre']], on = 'movie_id')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies['genre'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags are in json. We need to convert json to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty list\n",
    "genres = [] \n",
    "\n",
    "# extract genres\n",
    "for i in movies['genre']: \n",
    "  genres.append(list(json.loads(i).values())) \n",
    "\n",
    "# add to 'movies' dataframe  \n",
    "movies['genre_new'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1. Drop movies which doesn't have any genre information\n",
    "\n",
    "Dropping the movies which don't have any information about tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples with 0 genre tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all genre tags in a list\n",
    "all_genres = sum(genres,[])\n",
    "len(set(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are around 363 genres. This is too many. To reduce computing load, we will use top 50 gneres for prediciton. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = nltk.FreqDist(all_genres) \n",
    "\n",
    "# create dataframe\n",
    "all_genres_df = pd.DataFrame({'Genre': list(all_genres.keys()), \n",
    "                              'Count': list(all_genres.values())})\n",
    "\n",
    "g = all_genres_df.nlargest(columns=\"Count\", n = 50) \n",
    "\n",
    "plt.figure(figsize=(12,15)) \n",
    "ax = sns.barplot(data=g, x= \"Count\", y = \"Genre\") \n",
    "ax.set(ylabel = 'Count') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genre = list(g['Genre'])\n",
    "\n",
    "# an empty list\n",
    "tmp_genres = [] \n",
    "\n",
    "# extract genres\n",
    "for i in movies['genre_new']: \n",
    "  tmp_genres.append(list(set(i).intersection(set(selected_genre)))) \n",
    "\n",
    "# add to 'movies' dataframe  \n",
    "movies['chosen_genre'] = tmp_genres\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2. Drop rows that don't have any top-50 genres\n",
    "\n",
    "We dropped the genres which are not in the top 50 list. So some movies now don't belong to any of these genres. We need to drop these movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples with 0 genre tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3. Clean the movie plot\n",
    "\n",
    "This function drops the unnecessary characters from the movie plots. We will learn about regular expression later in this course. Use this function as a black box. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply `clean_text` funciton in the dataframe to clean the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_new['clean_plot'] = <write your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the clean plots now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a frequency distribution of words in all the plots and identify the most frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freq_words(x, terms = 30): \n",
    "  all_words = ' '.join([text for text in x]) \n",
    "  all_words = all_words.split() \n",
    "  fdist = nltk.FreqDist(all_words) \n",
    "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) \n",
    "  \n",
    "  # selecting top 20 most frequent words \n",
    "  d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "  \n",
    "  # visualize words and frequencies\n",
    "  plt.figure(figsize=(12,15)) \n",
    "  ax = sns.barplot(data=d, x= \"count\", y = \"word\") \n",
    "  ax.set(ylabel = 'Word') \n",
    "  plt.show()\n",
    "  \n",
    "# print 100 most frequent words \n",
    "freq_words(movies_new['clean_plot'], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the top words are the stopwords, which won't help in predicting the movie tags. So we need to drop them. A python package named `nltk` has a stop words remover. We will use that to drop all the stopwords from the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "\n",
    "Most of the frequent words are stop words. We will download the list of stop words from `nltk` library and remove them from plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "movies_new['clean_plot'] = movies_new['clean_plot'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the plots after removing the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding target variables\n",
    "\n",
    "We cannot use the text tags as targets directly in the model. We are required to convert the targets to multi-binary features. As we now have only 50 tags/genres, the number of target variables is 50. There is a 50-length output vector for each movie, where all the values will be zero except the corresponding movie tag position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(movies_new['chosen_genre'])\n",
    "\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(movies_new['chosen_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert text to feature vector\n",
    "\n",
    "We can't train the model directly from the text. We need to convert it to a numeric vector feature. To convert the text to a feature vector, we will use sklearn's `TfidfVectorizer`. This method converts a text data to a numeric vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T4. Create train (80%) and test (20%) split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = <write your code> \n",
    "\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5. Multi-label Model Training\n",
    "\n",
    "As we have multiple outputs (i.e., genres) for each movie, we will be using `MultiOutputClassifier` as it can learn multiple targets simultaneously. Internally it learns a model (aka base model) for every target. Let's use a decision tree classifier as a base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = <write your code>\n",
    "y_pred = <write your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T6. Measure Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = <write your code>\n",
    "print(f\"Acc: {acc:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T7. Qualitative evaluation: radnomly pick 10 plots, show their text, true genres, and predicted genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = remove_stopwords(q)\n",
    "    q_vec = <write your code>\n",
    "    q_pred = <write your code>\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10): \n",
    "    <write your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
