{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from sql_actions import PostInsert\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Username and Password\n",
    "user = getpass.getuser()\n",
    "pw = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "---\n",
    "This section we will import the CSVs into Pandas DataFrames to do data carpentry.\n",
    "\n",
    "# Contract Data\n",
    "\n",
    "For the contracts data, not much data wrangling is involved. Only the ordering and changing of datatypes will be involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contracts data\n",
    "contracts_df = pd.read_csv('data/FRAX-USD.csv')\n",
    "\n",
    "# Check data\n",
    "contracts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order columns\n",
    "con_order = [\"address\",\"base\",\"code\",\"created_at\",\"dynamic\",\"factory\",\n",
    "             \"id\",\"name\",\"namespace\",\"updated_at\"]\n",
    "\n",
    "# Order columns for data insert\n",
    "contracts_df = contracts_df[con_order]\n",
    "\n",
    "# Unix epoch start time\n",
    "start = datetime(1970, 1, 1)  \n",
    "\n",
    "# Convert to string\n",
    "contracts_df[[\"address\",\"code\"]] = contracts_df[[\"address\",\"code\"]].astype(str)\n",
    "contracts_df.updated_at = pd.to_datetime(contracts_df.updated_at, unit='s', utc=True)\n",
    "contracts_df.created_at = pd.to_datetime(contracts_df.created_at, unit='s', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data\n",
    "contracts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Insert SQL\n",
    "frax_price_insert = open('insert_sql/contracts_insert.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Data \n",
    "PostInsert.fast_insert_data(contracts_df, contract_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction data --> Rerun if memory issues occur\n",
    "transactions_df = pd.read_csv('data/frax-ethereum-transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transaction_id column\n",
    "transactions_df['transaction_id'] = transactions_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Transaction data\n",
    "transaction_order = [\"transaction_id\",\"access_list\",\"block_hash\",\"block_number\",\"block_time\",\"data\",\n",
    "                     \"from\",\"gas_limit\",\"gas_price\",\"gas_used\",\"hash\",\"index\",\n",
    "                     \"max_fee_per_gas\",\"max_priority_fee_per_gas\",\"nonce\",\n",
    "                     \"priority_fee_per_gas\",\"success\",\"to\",\"type\",\"value\"]\n",
    "\n",
    "transactions_df = transactions_df[transaction_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create block/transaction-id data\n",
    "trans_block = transactions_df[['transaction_id','block_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop block_hash column\n",
    "transaction_final = transactions_df.drop(['block_hash'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Insert SQL\n",
    "trans_insert = open('insert_sql/transactions_insert.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Transaction data\n",
    "PostInsert.fast_insert_data(transaction_final, trans_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Logs Data --> Rerun if memory issues occur\n",
    "logs_df = pd.read_csv('data/frax-ethereum-logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log_id column\n",
    "logs_df['log_id'] = logs_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order columns\n",
    "log_order = [\"log_id\",\"block_hash\",\"block_time\",\"contract_address\",\"data\",\"index\",\"topic1\" \n",
    "            ,\"topic2\",\"topic3\",\"topic4\",\"tx_hash\",\"tx_index\"]\n",
    "\n",
    "logs_df = logs_df[log_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create block/log-id data\n",
    "logs_block = logs_df[['log_id','block_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop block-hash column\n",
    "logs_final = logs_df.drop(['block_hash'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Insert SQL\n",
    "logs_insert = open('insert_sql/logs_insert.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Logs data\n",
    "PostInsert.fast_insert_data(logs_final, logs_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traces Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in seperately due to size  --> Rerun if memory issues occur\n",
    "traces_v1_df = pd.read_csv('data/frax-ethereum-traces.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_v2_df = pd.read_csv('data/frax-ethereum-traces-v2.csv')  # --> Rerun if memory issues occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "traces_df = pd.concat([traces_v1_df, traces_v2_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trace_id column\n",
    "traces_df['trace_id'] = traces_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Order\n",
    "traces_order =[\"trace_id\", \"block_hash\", \"block_number\", \"block_time\", \"call_type\"  \n",
    "                ,\"error\",\"from\",\"gas\",\"gas_used\",\"input\",\"output\",\"sub_traces\" \n",
    "                ,\"success\",\"to\",\"tx_hash\",\"tx_index\",\"tx_success\",\"type\",\"value\"]\n",
    "\n",
    "traces_df = traces_df[traces_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create block/trace-id data\n",
    "traces_block = traces_df[['trace_id','block_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop block-hash column\n",
    "traces_final = traces_df.drop(['block_hash'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Insert SQL\n",
    "traces_insert = open('insert_sql/traces_insert.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert traces data\n",
    "PostInsert.fast_insert_data(traces_final, traces_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Staging\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "main_df = pd.concat([trans_block['block_hash'], \n",
    "                     logs_block[\"block_hash\"], \n",
    "                     traces_block[\"block_hash\"]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate hash values\n",
    "main_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(main_df, trans_block, on=\"block_hash\", how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(main_df, traces_block, on='block_hash', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(main_df, logs_block, on='block_hash', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Insert SQL\n",
    "main_insert = open('insert_sql/main_insert.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data\n",
    "PostInsert.fast_insert_data(main_df, main_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Date Data --> Rerun if memory issues occur\n",
    "date_df = pd.read_csv('data/date_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Create date_id column\n",
    "logs_df['date_id'] = date_df.index + 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frax_price_insert = open('insert_sql/date_table.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert date data\n",
    "PostInsert.fast_insert_data(date_table_df, date_table_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRAX Price Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FRAX Price Data --> Rerun if memory issues occur\n",
    "frax_price_df = pd.read_csv('data/frax_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frax_price_insert = open('insert_sql/frax_price.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert frax price data\n",
    "PostInsert.fast_insert_data(frax_price_df, frax_price_insert, 50000, user, pw) # Uncomment to rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# FXS Price Data\n",
    "---\n",
    "\n",
    "# Load FXS Price Data --> Rerun if memory issues occur\n",
    "fxs_price_df = pd.read_csv('data/fxs_price.csv')\n",
    "\n",
    "fxs_price_insert = open('insert_sql/fxs_price.sql','r').read()\n",
    "\n",
    "# Insert fxs price data\n",
    "# PostInsert.fast_insert_data(fxs_price_df, fxs_price_insert, 50000, user, pw) # Uncomment to rerun.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
